trigger:
  branches:
    include:
    - main
    - bot/otelcollector-upgrade-*
    - dependabot*
pr:
  autoCancel: true
  branches:
    include:
    - main

variables:
  HELM_CHART_NAME: 'prometheus-collector'
  ARC_HELM_CHART_NAME: 'ama-metrics-arc'
  ACR_REGISTRY: 'containerinsightsprod.azurecr.io'
  ACR_REPOSITORY: '/public/azuremonitor/containerinsights/cidev/prometheus-collector/images'
  ACR_REPOSITORY_HELM: '/public/azuremonitor/containerinsights/cidev'
  MCR_REGISTRY: 'mcr.microsoft.com'
  MCR_REPOSITORY: '/azuremonitor/containerinsights/cidev/prometheus-collector/images'
  MCR_REPOSITORY_HELM: '/azuremonitor/containerinsights/cidev/prometheus-collector'
  MCR_REPOSITORY_HELM_DEPENDENCIES: '/azuremonitor/containerinsights/cidev'
  KUBE_STATE_METRICS_IMAGE: 'mcr.microsoft.com/oss/v2/kubernetes/kube-state-metrics:v2.17.0-4'
  NODE_EXPORTER_IMAGE: 'mcr.microsoft.com/oss/v2/prometheus/node-exporter:v1.9.1'
  IS_PR: $[eq(variables['Build.Reason'], 'PullRequest')]
  IS_MAIN_BRANCH: $[eq(variables['Build.SourceBranchName'], 'main')]
  IS_OTEL_UPGRADE_BRANCH: $[startsWith(variables['Build.SourceBranchName'], 'otelcollector-upgrade-')]
  BUILD_WINDOWS: true
  Codeql.Enabled: true
  GOLANG_VERSION: '1.24.11'
  FLUENTBIT_GOLANG_VERSION: '1.24.6'
  TESTKUBE_GOLANG_VERSION: '1.24.0'
  FLUENT_BIT_VERSION: '3.2.2'
  PROMETHEUS_VERSION: '3.2.1'
  HELM_VERSION: '3.12.3'
resources:
  repositories:
  - repository: 1ESPipelineTemplates
    type: git
    name: 1ESPipelineTemplates/1ESPipelineTemplates
    ref: refs/tags/release
extends:
  template: v1/1ES.Official.PipelineTemplate.yml@1ESPipelineTemplates
  parameters:
    featureFlags:
      WindowsHostVersion:
        Network: KS1
    pool:
      name: Azure-Pipelines-CI-Test-EO
      image: ci-1es-managed-ubuntu-2204
      os: linux
    sdl:
      sourceAnalysisPool:
        name: Azure-Pipelines-CI-Test-EO
        image: ci-1es-managed-windows-2022
        os: windows
      componentgovernance: 
        ignoreDirectories: 'mixins,internal,tools'
    customBuildTags:
    - ES365AIMigrationTooling

    stages:
    - stage: Build
      jobs:
      - job: Image_Tags_and_Ev2_Artifacts
        displayName: "Build: Set image tags and publish Ev2 artifacts"
        pool:
          name: Azure-Pipelines-CI-Test-EO
          image: ci-1es-managed-ubuntu-2204
          os: linux
        variables:
          skipComponentGovernanceDetection: true
        templateContext:
          outputs:
          - output: pipelineArtifact
            displayName: 'Ev2: publish Ev2 deployment artifacts'
            targetPath: '$(Build.ArtifactStagingDirectory)'
            artifactName: ev2-drop
        steps:
        - checkout: self
          submodules: true
        - bash: |
            if [ $(IS_PR) == "True" ]; then
              BRANCH_NAME=$(System.PullRequest.SourceBranch)
            else
              BRANCH_NAME=$(Build.SourceBranch)
              BRANCH_NAME=${BRANCH_NAME#refs/heads/}
            fi
            BRANCH_NAME=$(echo $BRANCH_NAME | tr / - | tr . - | tr _ - | cut -c1-90)
            COMMIT_SHA=$(echo $(Build.SourceVersion) | cut -b -8)
            DATE=$(TZ=America/Los_Angeles date +%m-%d-%Y)
            VERSION=$(cat $(Build.SourcesDirectory)/otelcollector/VERSION)
            SEMVER=$VERSION-$BRANCH_NAME-$DATE-$COMMIT_SHA
            LINUX_IMAGE_TAG=$SEMVER
            # Truncating to 128 characters as it is required by docker
            LINUX_IMAGE_TAG=$(echo "${LINUX_IMAGE_TAG}" | cut -c1-128)
            #Truncating this to 128 to add the arm/amd suffix
            LINUX_MULTIARCH_TAG_PREFIX=$(echo "${LINUX_IMAGE_TAG}" | cut -c1-124)
            #Truncating this to 124 to add the cfg suffix
            LINUX_IMAGE_TAG_PREFIX=$(echo "${LINUX_IMAGE_TAG}" | cut -c1-124)
            LINUX_CONFIG_READER_IMAGE_TAG=$LINUX_IMAGE_TAG_PREFIX-cfg
            LINUX_CCP_IMAGE_TAG=$LINUX_IMAGE_TAG_PREFIX-ccp
            LINUX_CCP_IMAGE_TAG=$LINUX_IMAGE_TAG_PREFIX-ccp
            LINUX_ARM64_IMAGE_TAG=$LINUX_IMAGE_TAG_PREFIX-arm
            LINUX_AMD64_IMAGE_TAG=$LINUX_IMAGE_TAG_PREFIX-amd
            #Truncating this to 113 to add the ref app suffices
            LINUX_REF_APP_IMAGE_TAG_PREFIX=$(echo "${LINUX_IMAGE_TAG}" | cut -c1-113)
            LINUX_REF_APP_GOLANG_IMAGE_TAG=$LINUX_REF_APP_IMAGE_TAG_PREFIX-ref-app-golang
            LINUX_REF_APP_PYTHON_IMAGE_TAG=$LINUX_REF_APP_IMAGE_TAG_PREFIX-ref-app-python
            # Truncating to 115 characters as it is required by docker (4 characters used in -win, 9 characters used in -ltsc2019/-ltsc2022, 10 characters used in -unsigned)
            WINDOWS_IMAGE_TAG_PREFIX=$(echo "${LINUX_IMAGE_TAG}" | cut -c1-105)
            WINDOWS_IMAGE_TAG=$WINDOWS_IMAGE_TAG_PREFIX-win
            #Truncating this to 112 characters to add the targetallocator suffix
            TARGET_ALLOCATOR_IMAGE_TAG_PREFIX=$(echo "${LINUX_IMAGE_TAG}" | cut -c1-112)
            TARGET_ALLOCATOR_IMAGE_TAG=$TARGET_ALLOCATOR_IMAGE_TAG_PREFIX-targetallocator
            #Truncating this 108 to characters to add the targetallocator-arm/amd suffix
            TARGET_ALLOCATOR_MULTIARCH_TAG_PREFIX=$(echo "${LINUX_IMAGE_TAG}" | cut -c1-108)
            TARGET_ALLOCATOR_ARM64_IMAGE_TAG=$TARGET_ALLOCATOR_MULTIARCH_TAG_PREFIX-targetallocator-arm
            TARGET_ALLOCATOR_AMD64_IMAGE_TAG=$TARGET_ALLOCATOR_MULTIARCH_TAG_PREFIX-targetallocator-amd
            #Truncating this to 113 to add the ref app suffices
            WIN_REF_APP_IMAGE_TAG_PREFIX=$(echo "${LINUX_IMAGE_TAG}" | cut -c1-107)
            WIN_REF_APP_GOLANG_IMAGE_TAG=$WIN_REF_APP_IMAGE_TAG_PREFIX-win-ref-app-golang
            WIN_REF_APP_PYTHON_IMAGE_TAG=$WIN_REF_APP_IMAGE_TAG_PREFIX-win-ref-app-python
            # Truncating to 119 characters as it is required by docker (9 characters used in -ltsc2019/-ltsc2022)
            WINDOWS_2019_BASE_IMAGE_VERSION=ltsc2019
            WINDOWS_2022_BASE_IMAGE_VERSION=ltsc2022
            #Truncating this to 123 characters to add the conf prefix
            ARC_CONFORMANCE_TAG_SUFFIX=$(echo "${LINUX_IMAGE_TAG}" | cut -c1-123)
            ARC_CONFORMANCE_IMAGE_TAG=conf-$ARC_CONFORMANCE_TAG_SUFFIX
            LINUX_FULL_IMAGE_NAME=$ACR_REGISTRY$ACR_REPOSITORY:$LINUX_IMAGE_TAG
            TARGET_ALLOCATOR_FULL_IMAGE_NAME=$ACR_REGISTRY$ACR_REPOSITORY:$TARGET_ALLOCATOR_IMAGE_TAG
            LINUX_CONFIG_READER_FULL_IMAGE_NAME=$ACR_REGISTRY$ACR_REPOSITORY:$LINUX_CONFIG_READER_IMAGE_TAG
            LINUX_CCP_FULL_IMAGE_NAME=$ACR_REGISTRY$ACR_REPOSITORY:$LINUX_CCP_IMAGE_TAG
            WINDOWS_FULL_IMAGE_NAME=$ACR_REGISTRY$ACR_REPOSITORY:$WINDOWS_IMAGE_TAG
            HELM_FULL_IMAGE_NAME=$ACR_REGISTRY$ACR_REPOSITORY_HELM/$HELM_CHART_NAME:$SEMVER
            ARC_HELM_FULL_IMAGE_NAME=$ACR_REGISTRY$ACR_REPOSITORY_HELM/$ARC_HELM_CHART_NAME:$SEMVER
            LINUX_REF_APP_GOLANG_FULL_IMAGE_NAME=$ACR_REGISTRY$ACR_REPOSITORY:$LINUX_REF_APP_GOLANG_IMAGE_TAG
            LINUX_REF_APP_PYTHON_FULL_IMAGE_NAME=$ACR_REGISTRY$ACR_REPOSITORY:$LINUX_REF_APP_PYTHON_IMAGE_TAG
            WINDOWS_REF_APP_GOLANG_FULL_IMAGE_NAME=$ACR_REGISTRY$ACR_REPOSITORY:$WIN_REF_APP_GOLANG_IMAGE_TAG
            WINDOWS_REF_APP_PYTHON_FULL_IMAGE_NAME=$ACR_REGISTRY$ACR_REPOSITORY:$WIN_REF_APP_PYTHON_IMAGE_TAG
            ARC_CONFORMANCE_FULL_IMAGE_NAME=$ACR_REGISTRY$ACR_REPOSITORY:$ARC_CONFORMANCE_IMAGE_TAG
            LINUX_ARM64_FULL_IMAGE_NAME=$ACR_REGISTRY$ACR_REPOSITORY:$LINUX_ARM64_IMAGE_TAG
            LINUX_AMD64_FULL_IMAGE_NAME=$ACR_REGISTRY$ACR_REPOSITORY:$LINUX_AMD64_IMAGE_TAG
            TARGET_ALLOCATOR_ARM64_FULL_IMAGE_NAME=$ACR_REGISTRY$ACR_REPOSITORY:$TARGET_ALLOCATOR_ARM64_IMAGE_TAG
            TARGET_ALLOCATOR_AMD64_FULL_IMAGE_NAME=$ACR_REGISTRY$ACR_REPOSITORY:$TARGET_ALLOCATOR_AMD64_IMAGE_TAG
            echo "##vso[build.updatebuildnumber]$SEMVER"
            echo "##vso[task.setvariable variable=SEMVER;isOutput=true]$SEMVER"
            echo "##vso[task.setvariable variable=LINUX_FULL_IMAGE_NAME;isOutput=true]$LINUX_FULL_IMAGE_NAME"
            echo "##vso[task.setvariable variable=TARGET_ALLOCATOR_IMAGE_TAG;isOutput=true]$TARGET_ALLOCATOR_IMAGE_TAG"
            echo "##vso[task.setvariable variable=LINUX_CONFIG_READER_IMAGE_TAG;isOutput=true]$LINUX_CONFIG_READER_IMAGE_TAG"
            echo "##vso[task.setvariable variable=TARGET_ALLOCATOR_FULL_IMAGE_NAME;isOutput=true]$TARGET_ALLOCATOR_FULL_IMAGE_NAME"
            echo "##vso[task.setvariable variable=LINUX_CONFIG_READER_FULL_IMAGE_NAME;isOutput=true]$LINUX_CONFIG_READER_FULL_IMAGE_NAME"
            echo "##vso[task.setvariable variable=LINUX_CCP_FULL_IMAGE_NAME;isOutput=true]$LINUX_CCP_FULL_IMAGE_NAME"
            echo "##vso[task.setvariable variable=WINDOWS_FULL_IMAGE_NAME;isOutput=true]$WINDOWS_FULL_IMAGE_NAME"
            echo "##vso[task.setvariable variable=LINUX_REF_APP_GOLANG_FULL_IMAGE_NAME;isOutput=true]$LINUX_REF_APP_GOLANG_FULL_IMAGE_NAME"
            echo "##vso[task.setvariable variable=LINUX_REF_APP_PYTHON_FULL_IMAGE_NAME;isOutput=true]$LINUX_REF_APP_PYTHON_FULL_IMAGE_NAME"
            echo "##vso[task.setvariable variable=WINDOWS_REF_APP_GOLANG_FULL_IMAGE_NAME;isOutput=true]$WINDOWS_REF_APP_GOLANG_FULL_IMAGE_NAME"
            echo "##vso[task.setvariable variable=WINDOWS_REF_APP_PYTHON_FULL_IMAGE_NAME;isOutput=true]$WINDOWS_REF_APP_PYTHON_FULL_IMAGE_NAME"
            echo "##vso[task.setvariable variable=WINDOWS_IMAGE_TAG;isOutput=true]$WINDOWS_IMAGE_TAG"
            echo "##vso[task.setvariable variable=WINDOWS_2019_BASE_IMAGE_VERSION;isOutput=true]$WINDOWS_2019_BASE_IMAGE_VERSION"
            echo "##vso[task.setvariable variable=WINDOWS_2022_BASE_IMAGE_VERSION;isOutput=true]$WINDOWS_2022_BASE_IMAGE_VERSION"
            echo "##vso[task.setvariable variable=HELM_CHART_NAME;isOutput=true]$HELM_CHART_NAME"
            echo "##vso[task.setvariable variable=ARC_HELM_CHART_NAME;isOutput=true]$ARC_HELM_CHART_NAME"
            echo "##vso[task.setvariable variable=HELM_FULL_IMAGE_NAME;isOutput=true]$HELM_FULL_IMAGE_NAME"
            echo "##vso[task.setvariable variable=ARC_HELM_FULL_IMAGE_NAME;isOutput=true]$ARC_HELM_FULL_IMAGE_NAME"
            echo "##vso[task.setvariable variable=ARC_CONFORMANCE_FULL_IMAGE_NAME;isOutput=true]$ARC_CONFORMANCE_FULL_IMAGE_NAME"
            echo "##vso[task.setvariable variable=LINUX_ARM64_FULL_IMAGE_NAME;isOutput=true]$LINUX_ARM64_FULL_IMAGE_NAME"
            echo "##vso[task.setvariable variable=LINUX_AMD64_FULL_IMAGE_NAME;isOutput=true]$LINUX_AMD64_FULL_IMAGE_NAME"
            echo "##vso[task.setvariable variable=TARGET_ALLOCATOR_ARM64_IMAGE_TAG;isOutput=true]$TARGET_ALLOCATOR_ARM64_IMAGE_TAG"
            echo "##vso[task.setvariable variable=TARGET_ALLOCATOR_AMD64_IMAGE_TAG;isOutput=true]$TARGET_ALLOCATOR_AMD64_IMAGE_TAG"
            echo "##vso[task.setvariable variable=TARGET_ALLOCATOR_ARM64_FULL_IMAGE_NAME;isOutput=true]$TARGET_ALLOCATOR_ARM64_FULL_IMAGE_NAME"
            echo "##vso[task.setvariable variable=TARGET_ALLOCATOR_AMD64_FULL_IMAGE_NAME;isOutput=true]$TARGET_ALLOCATOR_AMD64_FULL_IMAGE_NAME"
          displayName: 'Build: set image registry, repo, and tags'
          name: setup
        - bash: |
            cd .pipelines/deployment/ServiceGroupRoot/Scripts
            cp ../../../../otelcollector/deploy/chart/prometheus-collector prometheus-collector -r
            cp ../../../../otelcollector/deploy/addon-chart/azure-monitor-metrics-addon ama-metrics-arc -r
            export MCR_REPOSITORY='/azuremonitor/containerinsights/ciprod/prometheus-collector/images'
            export MCR_REPOSITORY_HELM_DEPENDENCIES='/azuremonitor/containerinsights/ciprod'
            export HELM_SEMVER=$SETUP_SEMVER
            export IMAGE_TAG=$SETUP_SEMVER
            export IMAGE_TAG_WINDOWS=$SETUP_WINDOWS_IMAGE_TAG
            env
            envsubst < prometheus-collector/Chart-template.yaml > prometheus-collector/Chart.yaml && envsubst < prometheus-collector/values-template.yaml > prometheus-collector/values.yaml
            export ARC_EXTENSION=true
            export HELM_CHART_NAME=$ARC_HELM_CHART_NAME
            export ARC_RESOURCE_ID="/subscriptions/9b96ebbd-c57a-42d1-bbe9-b69296e4c7fb/resourceGroups/ci-prod-arc-wcus/providers/Microsoft.Kubernetes/connectedClusters/ci-prod-arc-wcus"
            export ARC_REGION="westcentralus"
            envsubst < ama-metrics-arc/Chart-template.yaml > ama-metrics-arc/Chart.yaml && envsubst < ama-metrics-arc/values-template.yaml > ama-metrics-arc/values.yaml
            tar -czvf ../artifacts.tar.gz pushAgentToAcr.sh pushChartToAcr.sh prometheus-collector ama-metrics-arc
            cd $(Build.ArtifactStagingDirectory)
            cp $(Build.SourcesDirectory)/otelcollector/deploy/addon-chart/azure-monitor-metrics-addon azure-monitor-metrics-addon -r
            export HELM_CHART_NAME="ama-metrics"
            export ARC_EXTENSION=false
            export AKS_REGION="westeurope"
            export AKS_RESOURCE_ID="/subscriptions/9b96ebbd-c57a-42d1-bbe9-b69296e4c7fb/resourceGroups/ci-prod-aks-mac-weu-rg/providers/Microsoft.ContainerService/managedClusters/ci-prod-aks-mac-weu"
            envsubst < azure-monitor-metrics-addon/Chart-template.yaml > azure-monitor-metrics-addon/Chart.yaml && envsubst < azure-monitor-metrics-addon/values-template.yaml > azure-monitor-metrics-addon/values.yaml

            echo $(Build.BuildNumber) > "$(Build.SourcesDirectory)/.pipelines/deployment/ServiceGroupRoot/buildver.txt"
            echo $(Build.BuildNumber) > "$(Build.SourcesDirectory)/.pipelines/deployment/arc-extension-release/ServiceGroupRoot/buildver.txt"
          displayName: 'Ev2: package artifacts.tar.gz for prod release'
        - task: HelmInstaller@1
          displayName: 'CI/CD: Install Helm version for linting'
          condition: or(eq(variables.IS_PR, true), eq(variables.IS_MAIN_BRANCH, true))
          inputs:
            helmVersionToInstall: $(HELM_VERSION)
        - bash: |
            # Lint ama-metrics-arc chart (ARC extension)
            cd $(Build.SourcesDirectory)/.pipelines/deployment/ServiceGroupRoot/Scripts/ama-metrics-arc
            helm lint .
            if [ $? -ne 0 ]; then
              echo "Error: Helm lint failed for ama-metrics-arc chart"
              exit 1
            fi
            
            # Lint ama-metrics chart (AKS addon)
            cd $(Build.ArtifactStagingDirectory)/azure-monitor-metrics-addon
            helm lint .
            if [ $? -ne 0 ]; then
              echo "Error: Helm lint failed for ama-metrics chart"
              exit 1
            fi
            
            echo "All Helm charts passed linting!"
          displayName: "CI/CD: Lint Helm charts"
          condition: or(eq(variables.IS_PR, true), eq(variables.IS_MAIN_BRANCH, true))
        - bash: |
            cd $(Build.SourcesDirectory)/.pipelines/deployment/arc-extension-release/ServiceGroupRoot/Scripts
            tar -czvf ../extension-artifacts.tar.gz arcExtensionRelease.sh
          displayName: 'Ev2: package extension-artifacts.tar.gz for prod release'
        - task: CredScan@3
          displayName: "SDL : Run credscan"
        - task: CopyFiles@2
          displayName: "Ev2: copy Ev2 deployment artifacts to staging directory"
          inputs:
            SourceFolder: "$(Build.SourcesDirectory)/.pipelines/deployment"
            Contents: |
              **/*
            TargetFolder: '$(Build.ArtifactStagingDirectory)/deploy'
      - job: CreateSidecarArtifact
        displayName: "Create Sidecar YAML Artifact for Remote Write"
        pool:
          name: Azure-Pipelines-CI-Test-EO
          image: ci-1es-managed-ubuntu-2204
          os: linux
        templateContext:
          outputs:
          - output: pipelineArtifact
            displayName: 'Publish sidecar.yaml as an artifact'
            targetPath: '$(Build.ArtifactStagingDirectory)/remote-write'
            artifactName: 'remote-write-drop'
        steps:
        - task: CopyFiles@2
          displayName: "Copy sidecar.yaml to artifact staging directory"
          inputs:
            SourceFolder: '$(Build.SourcesDirectory)/internal/remotewrite'
            Contents: 'sidecar.yaml'
            TargetFolder: '$(Build.ArtifactStagingDirectory)/remote-write'

      - job: DevClusterHelmChartFiles
        displayName: "CI/CD: Export Helm Chart files for Dev Clusters"
        pool:
          name: Azure-Pipelines-CI-Test-EO
          image: ci-1es-managed-ubuntu-2204
          os: linux
        templateContext:
          outputs:
          - output: pipelineArtifact
            displayName: 'CI/CD: Publish Dev Cluster Helm Chart files'
            targetPath: '$(Build.ArtifactStagingDirectory)/helm-chart'
            artifactName: dev-cluster-helm-chart
        steps:
        - checkout: self
          persistCredentials: true
        - task: HelmInstaller@1
          displayName: Install Helm version
          inputs:
            helmVersionToInstall: $(HELM_VERSION)
        - bash: |
            # Get all releases and filter for proper semver versions (no pre-release tags)
            RETINA_VERSION=$(curl -sL https://api.github.com/repos/microsoft/retina/releases | jq -r '[.[] | select(.name | ("^[0-9]+\\.[0-9]+\\.[0-9]+$") and (contains("-") | not))][0].name')
            echo "##vso[task.setvariable variable=RETINA_VERSION]$RETINA_VERSION"
            echo $RETINA_VERSION 
            helm pull oci://ghcr.io/microsoft/retina/charts/retina --version $RETINA_VERSION --untar --untardir $(Build.SourcesDirectory)/otelcollector/deploy/retina/chart
            mv $(Build.SourcesDirectory)/otelcollector/deploy/retina/custom-files/network-observability-service.yaml $(Build.SourcesDirectory)/otelcollector/deploy/retina/chart/retina/templates/
            echo "##vso[task.setvariable variable=RETINA_VERSION;isOutput=true]$RETINA_VERSION"
          displayName: "CI/CD: Download Retina Chart"
          retryCountOnTaskFailure: 5
          name: setup
        - task: CopyFiles@2
          displayName: "CI/CD: Copy Retina Chart files to artifact staging directory"
          inputs:
            SourceFolder: '$(Build.SourcesDirectory)/otelcollector/deploy/retina/chart'
            Contents: |
              retina/**
            TargetFolder: '$(Build.ArtifactStagingDirectory)/helm-chart'
        - task: CopyFiles@2
          displayName: "CI/CD: Copy Dev Cluster Helm Chart files to artifact staging directory"
          inputs:
            SourceFolder: '$(Build.SourcesDirectory)/otelcollector/deploy/addon-chart'
            Contents: |
              azure-monitor-metrics-addon/**
            TargetFolder: '$(Build.ArtifactStagingDirectory)/helm-chart'

      - job: TestKubeTestFiles
        displayName: "CI/CD: Export TestKube test files for Deploy stage"
        pool:
          name: Azure-Pipelines-CI-Test-EO
          image: ci-1es-managed-ubuntu-2204
          os: linux
        templateContext:
          outputs:
          - output: pipelineArtifact
            displayName: 'CI/CD: Publish TestKube test files'
            targetPath: '$(Build.ArtifactStagingDirectory)/testkube-files'
            artifactName: testkube-test-files
        steps:
        - checkout: self
          persistCredentials: true
        - task: CopyFiles@2
          displayName: "CI/CD: Copy TestKube files to artifact staging directory"
          inputs:
            SourceFolder: '$(Build.SourcesDirectory)/otelcollector/test'
            Contents: |
              testkube/**
              test-cluster-yamls/**
            TargetFolder: '$(Build.ArtifactStagingDirectory)/testkube-files'

      - job: Linux_Golang_Reference_App
        displayName: "Build: linux golang reference app image"
        pool:
          name: Azure-Pipelines-CI-Test-EO
          image: ci-1es-managed-ubuntu-2204
          os: linux
        dependsOn: Image_Tags_and_Ev2_Artifacts
        variables:
          skipComponentGovernanceDetection: true
          LINUX_REF_APP_GOLANG_FULL_IMAGE_NAME: $[ dependencies.Image_Tags_and_Ev2_Artifacts.outputs['setup.LINUX_REF_APP_GOLANG_FULL_IMAGE_NAME'] ]
          DOCKER_BUILDKIT: 1
        condition: and(succeeded(), or(eq(variables.IS_PR, true), eq(variables.IS_MAIN_BRANCH, true)))
        steps:
        - checkout: self
          persistCredentials: true
        - bash: |
            export DOCKER_BUILDKIT=1
            mkdir -p $(Build.ArtifactStagingDirectory)/refappgolanglinux
            docker pull mcr.microsoft.com/azuremonitor/containerinsights/cidev/prometheus-collector/images:buildx-stable-1
            docker buildx create --name dockerbuilder --driver docker-container --driver-opt image=mcr.microsoft.com/azuremonitor/containerinsights/cidev/prometheus-collector/images:buildx-stable-1 --use 
            docker buildx inspect --bootstrap
            docker login containerinsightsprod.azurecr.io -u $(ACR_USERNAME) -p $(ACR_PASSWORD)
            docker buildx build . --file linux/Dockerfile -t $(LINUX_REF_APP_GOLANG_FULL_IMAGE_NAME) --build-arg "GOLANG_VERSION=$(GOLANG_VERSION)" --metadata-file $(Build.ArtifactStagingDirectory)/refappgolanglinux/metadata.json --push
            docker pull $(LINUX_REF_APP_GOLANG_FULL_IMAGE_NAME)
          workingDirectory: $(Build.SourcesDirectory)/internal/referenceapp/golang
          displayName: "Build: build and push reference app golang linux image to dev ACR"
        - bash: |
            MEDIA_TYPE=$(docker manifest inspect -v $(LINUX_REF_APP_GOLANG_FULL_IMAGE_NAME) | jq '.Descriptor.mediaType')
            DIGEST=$(docker manifest inspect -v $(LINUX_REF_APP_GOLANG_FULL_IMAGE_NAME) | jq '.Descriptor.digest')
            SIZE=$(docker manifest inspect -v $(LINUX_REF_APP_GOLANG_FULL_IMAGE_NAME) | jq '.Descriptor.size')
            cat <<EOF >>$(Build.ArtifactStagingDirectory)/refappgolanglinux/payload.json
            {"targetArtifact":{"mediaType":$MEDIA_TYPE,"digest":$DIGEST,"size":$SIZE}}
            EOF
          workingDirectory: $(Build.SourcesDirectory)/internal/referenceapp/golang
          displayName: "Build: Set values in payload.json for signing"
          condition: succeeded()
        - task: EsrpCodeSigning@5
          displayName: "ESRP CodeSigning for Prometheus Golang Linux Reference App"
          inputs:
            ConnectedServiceName: "ESRPServiceConnectionPrometheus"
            UseMSIAuthentication: true
            AppRegistrationClientId: 'bf21d5fe-78bd-45d2-b04d-c61f2e090c9a'
            AppRegistrationTenantId: '33e01921-4d64-4f8c-a055-5bdaffd5e33d'
            EsrpClientId: "73f8d5f9-b507-497f-b698-4ed00fcba5a3"
            AuthAKVName: 'ESRPPrometheusKVProd'
            AuthCertName: 'ESRPContainerImageSignCert'
            AuthSignCertName: ESRPReqPrometheusProdCert
            FolderPath: $(Build.ArtifactStagingDirectory)/refappgolanglinux/
            Pattern: "*.json"
            signConfigType: inlineSignParams
            inlineOperation: |
              [
                {
                    "keyCode": "CP-469451",
                    "operationSetCode": "NotaryCoseSign",
                    "parameters": [
                      {
                        "parameterName": "CoseFlags",
                        "parameterValue": "chainunprotected"
                      }
                    ],
                    "toolName": "sign",
                    "toolVersion": "1.0"
                }
              ]
            SessionTimeout: '60'
            MaxConcurrency: '50'
            MaxRetryAttempts: '5'
            PendingAnalysisWaitTimeoutMinutes: '5'
        - bash: |
            set -euxo pipefail
            curl -LO "https://github.com/oras-project/oras/releases/download/v1.0.0/oras_1.0.0_linux_amd64.tar.gz"
            mkdir -p oras-install/
            tar -zxf oras_1.0.0_*.tar.gz -C oras-install/
            sudo mv oras-install/oras /usr/local/bin/
            rm -rf oras_1.0.0_*.tar.gz oras-install/
            oras attach $(LINUX_REF_APP_GOLANG_FULL_IMAGE_NAME) \
              --artifact-type 'application/vnd.cncf.notary.signature' \
              ./payload.json:application/cose \
              -a "io.cncf.notary.x509chain.thumbprint#S256=[\"79E6A702361E1F60DAA84AEEC4CBF6F6420DE6BA\"]"
            oras attach $(LINUX_REF_APP_GOLANG_FULL_IMAGE_NAME) \
              --artifact-type 'application/vnd.microsoft.artifact.lifecycle' \
              --annotation "vnd.microsoft.artifact.lifecycle.end-of-life.date=$(date -u -d '-1 hour' +"%Y-%m-%dT%H:%M:%SZ")"
          workingDirectory: $(Build.ArtifactStagingDirectory)/refappgolanglinux/
          displayName: "ORAS Push Artifacts in $(Build.ArtifactStagingDirectory)/refappgolanglinux/"
          condition: succeeded()
      - job: Linux_Python_Reference_App
        displayName: "Build: linux python reference app image"
        pool:
          name: Azure-Pipelines-CI-Test-EO
          image: ci-1es-managed-ubuntu-2204
          os: linux
        dependsOn: Image_Tags_and_Ev2_Artifacts
        variables:
          skipComponentGovernanceDetection: true
          LINUX_REF_APP_PYTHON_FULL_IMAGE_NAME: $[ dependencies.Image_Tags_and_Ev2_Artifacts.outputs['setup.LINUX_REF_APP_PYTHON_FULL_IMAGE_NAME'] ]
          DOCKER_BUILDKIT: 1
        condition: and(succeeded(), or(eq(variables.IS_PR, true), eq(variables.IS_MAIN_BRANCH, true)))
        steps:
        - checkout: self
          persistCredentials: true
        - bash: |
            mkdir -p $(Build.ArtifactStagingDirectory)/refapppythonlinux
            docker pull mcr.microsoft.com/azuremonitor/containerinsights/cidev/prometheus-collector/images:buildx-stable-1
            docker buildx create --name dockerbuilder --driver docker-container --driver-opt image=mcr.microsoft.com/azuremonitor/containerinsights/cidev/prometheus-collector/images:buildx-stable-1 --use 
            docker buildx inspect --bootstrap
            docker login containerinsightsprod.azurecr.io -u $(ACR_USERNAME) -p $(ACR_PASSWORD)
            docker buildx build . --file linux/Dockerfile -t $(LINUX_REF_APP_PYTHON_FULL_IMAGE_NAME) --build-arg "GOLANG_VERSION=$(GOLANG_VERSION)" --metadata-file $(Build.ArtifactStagingDirectory)/refapppythonlinux/metadata.json --push
            docker pull $(LINUX_REF_APP_PYTHON_FULL_IMAGE_NAME)  
          workingDirectory: $(Build.SourcesDirectory)/internal/referenceapp/python
          displayName: "Build: build and push reference app python linux image to dev ACR"
        - bash: |
            MEDIA_TYPE=$(docker manifest inspect -v $(LINUX_REF_APP_PYTHON_FULL_IMAGE_NAME) | jq '.Descriptor.mediaType')
            DIGEST=$(docker manifest inspect -v $(LINUX_REF_APP_PYTHON_FULL_IMAGE_NAME) | jq '.Descriptor.digest')
            SIZE=$(docker manifest inspect -v $(LINUX_REF_APP_PYTHON_FULL_IMAGE_NAME) | jq '.Descriptor.size')
            cat <<EOF >>$(Build.ArtifactStagingDirectory)/refapppythonlinux/payload.json
            {"targetArtifact":{"mediaType":$MEDIA_TYPE,"digest":$DIGEST,"size":$SIZE}}
            EOF
          workingDirectory: $(Build.SourcesDirectory)/internal/referenceapp/python
          displayName: "Build: Set values in payload.json for signing"
          condition: succeeded()
        - task: EsrpCodeSigning@5
          displayName: "ESRP CodeSigning for Prometheus Python Linux Reference App"
          inputs:
            ConnectedServiceName: "ESRPServiceConnectionPrometheus"
            UseMSIAuthentication: true
            AppRegistrationClientId: 'bf21d5fe-78bd-45d2-b04d-c61f2e090c9a'
            AppRegistrationTenantId: '33e01921-4d64-4f8c-a055-5bdaffd5e33d'
            EsrpClientId: "73f8d5f9-b507-497f-b698-4ed00fcba5a3"
            AuthAKVName: 'ESRPPrometheusKVProd'
            AuthCertName: 'ESRPContainerImageSignCert'
            AuthSignCertName: 'ESRPReqPrometheusProdCert'
            FolderPath: $(Build.ArtifactStagingDirectory)/refapppythonlinux/
            Pattern: "*.json"
            signConfigType: inlineSignParams
            inlineOperation: |
              [
                {
                    "keyCode": "CP-469451",
                    "operationSetCode": "NotaryCoseSign",
                    "parameters": [
                      {
                        "parameterName": "CoseFlags",
                        "parameterValue": "chainunprotected"
                      }
                    ],
                    "toolName": "sign",
                    "toolVersion": "1.0"
                }
              ]
            SessionTimeout: '60'
            MaxConcurrency: '50'
            MaxRetryAttempts: '5'
            PendingAnalysisWaitTimeoutMinutes: '5'
        - bash: |
            set -euxo pipefail
            curl -LO "https://github.com/oras-project/oras/releases/download/v1.0.0/oras_1.0.0_linux_amd64.tar.gz"
            mkdir -p oras-install/
            tar -zxf oras_1.0.0_*.tar.gz -C oras-install/
            sudo mv oras-install/oras /usr/local/bin/
            rm -rf oras_1.0.0_*.tar.gz oras-install/
            oras attach $(LINUX_REF_APP_PYTHON_FULL_IMAGE_NAME) \
              --artifact-type 'application/vnd.cncf.notary.signature' \
              ./payload.json:application/cose \
              -a "io.cncf.notary.x509chain.thumbprint#S256=[\"79E6A702361E1F60DAA84AEEC4CBF6F6420DE6BA\"]"
            oras attach $(LINUX_REF_APP_PYTHON_FULL_IMAGE_NAME) \
              --artifact-type 'application/vnd.microsoft.artifact.lifecycle' \
              --annotation "vnd.microsoft.artifact.lifecycle.end-of-life.date=$(date -u -d '-1 hour' +"%Y-%m-%dT%H:%M:%SZ")"
          workingDirectory: $(Build.ArtifactStagingDirectory)/refapppythonlinux/
          displayName: "ORAS Push Artifacts in $(Build.ArtifactStagingDirectory)/refapppythonlinux/"
          condition: succeeded()
      - job: Golang_Windows_Reference_App
        displayName: "Build: windows golang reference app image"
        pool:
          name: Azure-Pipelines-CI-Test-EO
          image: ci-1es-managed-windows-2022
          os: windows
        dependsOn: Image_Tags_and_Ev2_Artifacts
        variables:
          WINDOWS_REF_APP_GOLANG_FULL_IMAGE_NAME: $[ dependencies.Image_Tags_and_Ev2_Artifacts.outputs['setup.WINDOWS_REF_APP_GOLANG_FULL_IMAGE_NAME'] ]
          skipComponentGovernanceDetection: true
        condition: and(succeeded(), or(eq(variables.IS_PR, true), eq(variables.IS_MAIN_BRANCH, true)))
        steps:
        - powershell: |
            New-Item -Path "$(Build.ArtifactStagingDirectory)" -Name "refappgolangwindows" -ItemType "directory"
            docker build . --isolation=hyperv --file windows/Dockerfile -t $(WINDOWS_REF_APP_GOLANG_FULL_IMAGE_NAME)
            docker login containerinsightsprod.azurecr.io -u $(ACR_USERNAME) -p $(ACR_PASSWORD)
            docker push $(WINDOWS_REF_APP_GOLANG_FULL_IMAGE_NAME)
            docker pull $(WINDOWS_REF_APP_GOLANG_FULL_IMAGE_NAME)
          displayName: "Build: build and push reference app golang windows image to dev ACR"
          workingDirectory: $(Build.SourcesDirectory)/internal/referenceapp/golang
        - powershell: |
            $output = docker manifest inspect -v $(WINDOWS_REF_APP_GOLANG_FULL_IMAGE_NAME) | ConvertFrom-Json
            $firstManifest = $output[0]
            $MEDIA_TYPE = $firstManifest.Descriptor.mediaType
            $DIGEST = $firstManifest.Descriptor.digest
            $SIZE = $firstManifest.Descriptor.size
            $payload = @{
                targetArtifact = @{
                    mediaType = $MEDIA_TYPE
                    digest = $DIGEST
                    size = $SIZE
                }
            } | ConvertTo-Json
            $payload | Out-File -FilePath "$(Build.ArtifactStagingDirectory)/refappgolangwindows/payload.json"
          workingDirectory: $(Build.SourcesDirectory)/internal/referenceapp/golang
          displayName: "Build the payload json file"
          condition: succeeded()
        - task: EsrpCodeSigning@5
          displayName: "ESRP CodeSigning for Prometheus Golang Windows Reference App"
          inputs:
            ConnectedServiceName: "ESRPServiceConnectionPrometheus"
            UseMSIAuthentication: true
            AppRegistrationClientId: 'bf21d5fe-78bd-45d2-b04d-c61f2e090c9a'
            AppRegistrationTenantId: '33e01921-4d64-4f8c-a055-5bdaffd5e33d'
            EsrpClientId: "73f8d5f9-b507-497f-b698-4ed00fcba5a3"
            AuthAKVName: 'ESRPPrometheusKVProd'
            AuthCertName: 'ESRPContainerImageSignCert'
            AuthSignCertName: 'ESRPReqPrometheusProdCert'
            FolderPath: $(Build.ArtifactStagingDirectory)/refappgolangwindows/
            Pattern: "*.json"
            signConfigType: inlineSignParams
            inlineOperation: |
              [
                {
                    "keyCode": "CP-469451",
                    "operationSetCode": "NotaryCoseSign",
                    "parameters": [
                      {
                        "parameterName": "CoseFlags",
                        "parameterValue": "chainunprotected"
                      }
                    ],
                    "toolName": "sign",
                    "toolVersion": "1.0"
                }
              ]
            SessionTimeout: '60'
            MaxConcurrency: '50'
            MaxRetryAttempts: '5'
            PendingAnalysisWaitTimeoutMinutes: '5'
        - powershell: |
            curl.exe -sLO  "https://github.com/oras-project/oras/releases/download/v1.0.0/oras_1.0.0_windows_amd64.zip"
            $currentDirectory = Get-Location
            Expand-Archive -Path $currentDirectory\oras_1.0.0_windows_amd64.zip -DestinationPath . -Force
            New-Item -ItemType Directory -Force -Path $env:USERPROFILE\bin
            Copy-Item -Path $currentDirectory\oras.exe -Destination "$env:USERPROFILE\bin\"
            $env:PATH = "$env:USERPROFILE\bin;$env:PATH"
            oras attach $(WINDOWS_REF_APP_GOLANG_FULL_IMAGE_NAME) --artifact-type application/vnd.cncf.notary.signature ./payload.json:application/cose -a io.cncf.notary.x509chain.thumbprint#S256=[\""79E6A702361E1F60DAA84AEEC4CBF6F6420DE6BA\""]
            oras attach $(WINDOWS_REF_APP_GOLANG_FULL_IMAGE_NAME) --artifact-type 'application/vnd.microsoft.artifact.lifecycle' --annotation "vnd.microsoft.artifact.lifecycle.end-of-life.date=$(powershell -Command "(Get-Date).AddHours(-1).ToString('yyyy-MM-ddTHH:mm:ssZ')")"          
          workingDirectory: $(Build.ArtifactStagingDirectory)/refappgolangwindows/
          displayName: "Download, install Oras and run oras attach"
          condition: succeeded()
      - job: Windows_Python_Reference_App
        displayName: "Build: windows python reference app image"
        pool:
          name: Azure-Pipelines-CI-Test-EO
          image: ci-1es-managed-windows-2022
          os: windows
        dependsOn: Image_Tags_and_Ev2_Artifacts
        variables:
          WINDOWS_REF_APP_PYTHON_FULL_IMAGE_NAME: $[ dependencies.Image_Tags_and_Ev2_Artifacts.outputs['setup.WINDOWS_REF_APP_PYTHON_FULL_IMAGE_NAME'] ]
          skipComponentGovernanceDetection: true
        condition: and(succeeded(), or(eq(variables.IS_PR, true), eq(variables.IS_MAIN_BRANCH, true)))
        steps:
        - powershell: |
            New-Item -Path "$(Build.ArtifactStagingDirectory)" -Name "refapppythonwindows" -ItemType "directory"
            docker build . --isolation=hyperv --file windows/Dockerfile -t $(WINDOWS_REF_APP_PYTHON_FULL_IMAGE_NAME)
            docker login containerinsightsprod.azurecr.io -u $(ACR_USERNAME) -p $(ACR_PASSWORD)
            docker push $(WINDOWS_REF_APP_PYTHON_FULL_IMAGE_NAME)
            docker pull $(WINDOWS_REF_APP_PYTHON_FULL_IMAGE_NAME)
          displayName: "Build: build and push reference app python windows image to dev ACR"
          workingDirectory: $(Build.SourcesDirectory)/internal/referenceapp/python
        - powershell: |
            $output = docker manifest inspect -v $(WINDOWS_REF_APP_PYTHON_FULL_IMAGE_NAME) | ConvertFrom-Json
            $firstManifest = $output[0]
            $MEDIA_TYPE = $firstManifest.Descriptor.mediaType
            $DIGEST = $firstManifest.Descriptor.digest
            $SIZE = $firstManifest.Descriptor.size
            $payload = @{
                targetArtifact = @{
                    mediaType = $MEDIA_TYPE
                    digest = $DIGEST
                    size = $SIZE
                }
            } | ConvertTo-Json
            $payload | Out-File -FilePath "$(Build.ArtifactStagingDirectory)/refapppythonwindows/payload.json"
          workingDirectory: $(Build.SourcesDirectory)/internal/referenceapp/python
          displayName: "Build the payload json file"
          condition: succeeded()
        - task: EsrpCodeSigning@5
          displayName: "ESRP CodeSigning for Prometheus Python Windows Reference App"
          inputs:
            ConnectedServiceName: "ESRPServiceConnectionPrometheus"
            UseMSIAuthentication: true
            AppRegistrationClientId: 'bf21d5fe-78bd-45d2-b04d-c61f2e090c9a'
            AppRegistrationTenantId: '33e01921-4d64-4f8c-a055-5bdaffd5e33d'
            EsrpClientId: "73f8d5f9-b507-497f-b698-4ed00fcba5a3"
            AuthAKVName: 'ESRPPrometheusKVProd'
            AuthCertName: 'ESRPContainerImageSignCert'
            AuthSignCertName: 'ESRPReqPrometheusProdCert'
            FolderPath: $(Build.ArtifactStagingDirectory)/refapppythonwindows/
            Pattern: "*.json"
            signConfigType: inlineSignParams
            inlineOperation: |
              [
                {
                    "keyCode": "CP-469451",
                    "operationSetCode": "NotaryCoseSign",
                    "parameters": [
                      {
                        "parameterName": "CoseFlags",
                        "parameterValue": "chainunprotected"
                      }
                    ],
                    "toolName": "sign",
                    "toolVersion": "1.0"
                }
              ]
            SessionTimeout: '60'
            MaxConcurrency: '50'
            MaxRetryAttempts: '5'
            PendingAnalysisWaitTimeoutMinutes: '5'
        - powershell: |
            curl.exe -sLO  "https://github.com/oras-project/oras/releases/download/v1.0.0/oras_1.0.0_windows_amd64.zip"
            $currentDirectory = Get-Location
            Expand-Archive -Path $currentDirectory\oras_1.0.0_windows_amd64.zip -DestinationPath . -Force
            New-Item -ItemType Directory -Force -Path $env:USERPROFILE\bin
            Copy-Item -Path $currentDirectory\oras.exe -Destination "$env:USERPROFILE\bin\"
            $env:PATH = "$env:USERPROFILE\bin;$env:PATH"
            oras attach $(WINDOWS_REF_APP_PYTHON_FULL_IMAGE_NAME) --artifact-type application/vnd.cncf.notary.signature ./payload.json:application/cose -a io.cncf.notary.x509chain.thumbprint#S256=[\""79E6A702361E1F60DAA84AEEC4CBF6F6420DE6BA\""]
            oras attach $(WINDOWS_REF_APP_PYTHON_FULL_IMAGE_NAME) --artifact-type 'application/vnd.microsoft.artifact.lifecycle' --annotation "vnd.microsoft.artifact.lifecycle.end-of-life.date=$(powershell -Command "(Get-Date).AddHours(-1).ToString('yyyy-MM-ddTHH:mm:ssZ')")"          
          workingDirectory: $(Build.ArtifactStagingDirectory)/refapppythonwindows/
          displayName: "Download, install Oras and run oras attach"
          condition: succeeded()
      - job: Arc_Conformace_Test_Image
        displayName: "Build: Arc Conformance Test Image"
        pool:
          name: Azure-Pipelines-CI-Test-EO
          image: ci-1es-managed-ubuntu-2204
          os: linux
        dependsOn: Image_Tags_and_Ev2_Artifacts
        variables:
          skipComponentGovernanceDetection: true
          ARC_CONFORMANCE_FULL_IMAGE_NAME: $[ dependencies.Image_Tags_and_Ev2_Artifacts.outputs['setup.ARC_CONFORMANCE_FULL_IMAGE_NAME'] ]
          DOCKER_BUILDKIT: 1
        condition: and(succeeded(), or(eq(variables.IS_PR, true), eq(variables.IS_MAIN_BRANCH, true)))
        steps:
        - checkout: self
          persistCredentials: true
        - bash: |
            docker pull mcr.microsoft.com/azuremonitor/containerinsights/cidev/prometheus-collector/images:buildx-stable-1
            docker buildx create --name dockerbuilder --driver docker-container --driver-opt image=mcr.microsoft.com/azuremonitor/containerinsights/cidev/prometheus-collector/images:buildx-stable-1 --use 
            docker buildx inspect --bootstrap
            docker login containerinsightsprod.azurecr.io -u $(ACR_USERNAME) -p $(ACR_PASSWORD)
            docker buildx build . -f otelcollector/test/arc-conformance/Dockerfile -t $(ARC_CONFORMANCE_FULL_IMAGE_NAME) --build-arg "GOLANG_VERSION=$(TESTKUBE_GOLANG_VERSION)" --push
            docker pull $(ARC_CONFORMANCE_FULL_IMAGE_NAME)  
          workingDirectory: $(Build.SourcesDirectory)/
          displayName: "Build: build and push Arc conformance test image to dev ACR"
      - job: SDL_Policheck_Scan
        displayName: "SDL: policheck scanning"
        pool:
          name: Azure-Pipelines-CI-Test-EO
          image: ci-1es-managed-windows-2022
          os: windows
        variables:
          skipComponentGovernanceDetection: true
        condition: and(succeeded(), or(eq(variables.IS_PR, true), eq(variables.IS_MAIN_BRANCH, true)))
        steps:
        - checkout: self
          submodules: true
        - task: PoliCheck@2
          displayName: "SDL : Run PoliCheck"
          inputs:
            targetType: 'F'
            targetArgument: '$(Build.SourcesDirectory)'
      - job: SDL_Binary_Scan
        displayName: "SDL: linux binary scanning"
        pool:
          name: Azure-Pipelines-CI-Test-EO
          image: ci-1es-managed-ubuntu-2204
          os: linux
        variables:
          skipComponentGovernanceDetection: true
        condition: and(succeeded(), or(eq(variables.IS_PR, true), eq(variables.IS_MAIN_BRANCH, true)))
        steps:
        - checkout: self
          submodules: true
        - task: CodeQL3000Init@0
          displayName: 'SDL: init codeql'
        - bash: |
            set -e
            wget -q https://go.dev/dl/go$(GOLANG_VERSION).linux-amd64.tar.gz
            sudo rm -rf /usr/local/go
            sudo tar -C /usr/local -xzf go$(GOLANG_VERSION).linux-amd64.tar.gz
            echo "##vso[task.prependpath]/usr/local/go/bin"
            go version
          displayName: "Build: install golang $(GOLANG_VERSION)"
        - bash: |
            sudo apt-get install build-essential -y
            make
          workingDirectory: $(Build.SourcesDirectory)/otelcollector/opentelemetry-collector-builder/
          displayName: "SDL: build otelcollector, promconfigvalidator, targetallocator, and fluent-bit plugin for scanning"
          retryCountOnTaskFailure: 1
        - task: BinSkim@4
          displayName: 'SDL: run binskim'
          inputs:
            InputType: 'CommandLine'
            arguments: 'analyze --rich-return-code $(Build.SourcesDirectory)/otelcollector/opentelemetry-collector-builder/otelcollector $(Build.SourcesDirectory)/otelcollector/prom-config-validator-builder/promconfigvalidator $(Build.SourcesDirectory)/otelcollector/otel-allocator/targetallocator $(Build.SourcesDirectory)/otelcollector/fluent-bit/src/out_appinsights.so'
          retryCountOnTaskFailure: 1
        - task: ESLint@1
          displayName: 'Run ESLint'
          inputs:
            Configuration: required
            EnableExclusions: false
          retryCountOnTaskFailure: 1
        - task: Armory@2
          displayName: 'Run ARMory'
          inputs:
            toolVersion: Latest
            targetDirectory: '$(Build.SourcesDirectory)'
          retryCountOnTaskFailure: 1
        - task: Gosec@1
          displayName: 'SDL: run gosec'
          inputs:
            targetPattern: 'gosecPattern'
            targetGosecPattern: '$(Build.SourcesDirectory)/otelcollector'
          retryCountOnTaskFailure: 1
        - bash: |
            wget https://github.com/microsoft/DevSkim/releases/download/v0.6.9/DevSkim_linux_0.6.9.zip
            unzip DevSkim_linux_0.6.9.zip
            chmod 775 DevSkim_linux_0.6.9/devskim
            ./DevSkim_linux_0.6.9/devskim analyze $(Build.SourcesDirectory)/otelcollector --ignore-globs **/deploy/dashboard/**,**/react/static/** --severity critical,important
          displayName: 'SDL: run devskim'
          workingDirectory: $(Build.SourcesDirectory)
          retryCountOnTaskFailure: 1
        - bash: |
            sudo gem install brakeman -v 5.4.1
            brakeman $(Build.SourcesDirectory)/otelcollector/configmapparser --force
          displayName: 'SDL: run brakeman'
          retryCountOnTaskFailure: 1
      - job: Linux_Prometheus_Collector_ARM64
        displayName: 'Build: linux ARM64 prometheus-collector image'
        pool:
          name: Azure-Pipelines-ARM-CI-Test-EO
          os: linux
          hostArchitecture: Arm64
          image: ci-1es-managed-arm64-ubuntu--2204
        dependsOn: Image_Tags_and_Ev2_Artifacts
        variables:
          LINUX_FULL_IMAGE_NAME: $[ dependencies.Image_Tags_and_Ev2_Artifacts.outputs['setup.LINUX_FULL_IMAGE_NAME'] ]
          LINUX_ARM64_FULL_IMAGE_NAME: $[ dependencies.Image_Tags_and_Ev2_Artifacts.outputs['setup.LINUX_ARM64_FULL_IMAGE_NAME'] ]
          DOCKER_BUILDKIT: 1
        steps:
        - checkout: self
          submodules: true
        - task: CodeQL3000Init@0
          displayName: 'SDL: init codeql'
        - bash: |
            set -e
            wget -q https://go.dev/dl/go$(GOLANG_VERSION).linux-arm64.tar.gz
            sudo rm -rf /usr/local/go
            sudo tar -C /usr/local -xzf go$(GOLANG_VERSION).linux-arm64.tar.gz
            export PATH="/usr/local/go/bin:${PATH}"
            echo "##vso[task.prependpath]/usr/local/go/bin"
            go version
          displayName: "Build: install golang $(GOLANG_VERSION)"
        - bash: |
            # Add Docker's official GPG key:
            # sudo apt-get update
            # sudo apt-get install ca-certificates curl -y
            # sudo install -m 0755 -d /etc/apt/keyrings
            # sudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc
            # sudo chmod a+r /etc/apt/keyrings/docker.asc
            # # Add the repository to Apt sources:
            # echo "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu $(. /etc/os-release && echo "${UBUNTU_CODENAME:-$VERSION_CODENAME}") stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
            # sudo apt-get update
            # sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin -y
            echo "=== Docker Version Info (ARM64 Agent) ==="
            sudo docker version
            echo "==========================================="
            
            mkdir -p $(Build.ArtifactStagingDirectory)/linux
            sudo docker login containerinsightsprod.azurecr.io -u $(ACR_USERNAME) -p $(ACR_PASSWORD)
            sudo docker build . --file ./build/linux/Dockerfile -t $(LINUX_ARM64_FULL_IMAGE_NAME) --build-arg "GOLANG_VERSION=$(GOLANG_VERSION)" --build-arg "FLUENTBIT_GOLANG_VERSION=$(FLUENTBIT_GOLANG_VERSION)" --build-arg "FLUENT_BIT_VERSION=$(FLUENT_BIT_VERSION)" --build-arg "PROMETHEUS_VERSION=$(PROMETHEUS_VERSION)" --metadata-file $(Build.ArtifactStagingDirectory)/linux/metadata.json --push
            if [ $? -ne 0 ]; then
              echo "Error: Docker build failed."
              exit 1
            fi
          retryCountOnTaskFailure: 1
          workingDirectory: $(Build.SourcesDirectory)/otelcollector/
          displayName: 'Build: build and push image to dev ACR'
      - job: Linux_Prometheus_Collector_AMD64
        displayName: 'Build: linux AMD64 prometheus-collector image'
        pool:
          name: Azure-Pipelines-CI-Test-EO
          image: ci-1es-managed-ubuntu-2204
          os: linux
        dependsOn: Image_Tags_and_Ev2_Artifacts
        variables:
          LINUX_FULL_IMAGE_NAME: $[ dependencies.Image_Tags_and_Ev2_Artifacts.outputs['setup.LINUX_FULL_IMAGE_NAME'] ]
          LINUX_AMD64_FULL_IMAGE_NAME: $[ dependencies.Image_Tags_and_Ev2_Artifacts.outputs['setup.LINUX_AMD64_FULL_IMAGE_NAME'] ]
          DOCKER_BUILDKIT: 1
        steps:
        - checkout: self
          submodules: true
        - task: CodeQL3000Init@0
          displayName: 'SDL: init codeql'
        - bash: |
            set -e
            wget -q https://go.dev/dl/go$(GOLANG_VERSION).linux-amd64.tar.gz
            sudo rm -rf /usr/local/go
            sudo tar -C /usr/local -xzf go$(GOLANG_VERSION).linux-amd64.tar.gz
            echo "##vso[task.prependpath]/usr/local/go/bin"
            go version
          displayName: "Build: install golang $(GOLANG_VERSION)"
        - bash: |
            echo "=== Docker Version Info (AMD64 Agent) ==="
            docker version
            echo "==========================================="
            
            mkdir -p $(Build.ArtifactStagingDirectory)/linux
  
            docker system prune --all -f
            docker login containerinsightsprod.azurecr.io -u $(ACR_USERNAME) -p $(ACR_PASSWORD)
            docker build . --file ./build/linux/Dockerfile -t $(LINUX_AMD64_FULL_IMAGE_NAME) --build-arg "GOLANG_VERSION=$(GOLANG_VERSION)" --build-arg "FLUENTBIT_GOLANG_VERSION=$(FLUENTBIT_GOLANG_VERSION)" --build-arg "FLUENT_BIT_VERSION=$(FLUENT_BIT_VERSION)" --build-arg "PROMETHEUS_VERSION=$(PROMETHEUS_VERSION)" --metadata-file $(Build.ArtifactStagingDirectory)/linux/metadata.json --push
            if [ $? -ne 0 ]; then
              echo "Error: Docker build failed."
              exit 1
            fi
          retryCountOnTaskFailure: 1
          workingDirectory: $(Build.SourcesDirectory)/otelcollector/
          displayName: "Build: build and push image to dev ACR"
      - job: Linux_Prometheus_Collector
        displayName: 'Build: linux prometheus-collector image'
        pool:
          name: Azure-Pipelines-CI-Test-EO
          image: ci-1es-managed-ubuntu-2204
          os: linux
        dependsOn:
        - Image_Tags_and_Ev2_Artifacts
        - Linux_Prometheus_Collector_AMD64
        - Linux_Prometheus_Collector_ARM64
        variables:
          LINUX_FULL_IMAGE_NAME: $[ dependencies.Image_Tags_and_Ev2_Artifacts.outputs['setup.LINUX_FULL_IMAGE_NAME'] ]
          LINUX_AMD64_FULL_IMAGE_NAME: $[ dependencies.Image_Tags_and_Ev2_Artifacts.outputs['setup.LINUX_AMD64_FULL_IMAGE_NAME'] ]
          LINUX_ARM64_FULL_IMAGE_NAME: $[ dependencies.Image_Tags_and_Ev2_Artifacts.outputs['setup.LINUX_ARM64_FULL_IMAGE_NAME'] ]
          DOCKER_BUILDKIT: 1
        templateContext:
          outputs:
          - output: pipelineArtifact
            displayName: 'Ev2: Publish image artifacts'
            condition: and(succeeded(), and(eq(variables.IS_PR, false), eq(variables.IS_MAIN_BRANCH, true)))
            targetPath: '$(Build.ArtifactStagingDirectory)'
            artifactName: linux-drop
        steps:
        - checkout: self
          submodules: true
        - task: CodeQL3000Init@0
          displayName: 'SDL: init codeql'
        - bash: |
            set -e
            wget -q https://go.dev/dl/go$(GOLANG_VERSION).linux-amd64.tar.gz
            sudo rm -rf /usr/local/go
            sudo tar -C /usr/local -xzf go$(GOLANG_VERSION).linux-amd64.tar.gz
            echo "##vso[task.prependpath]/usr/local/go/bin"
            go version
          displayName: "Build: install golang $(GOLANG_VERSION)"
        - bash: |
            mkdir -p $(Build.ArtifactStagingDirectory)/linux
            docker login containerinsightsprod.azurecr.io -u $(ACR_USERNAME) -p $(ACR_PASSWORD)
            docker buildx imagetools create -t $(LINUX_FULL_IMAGE_NAME) $(LINUX_AMD64_FULL_IMAGE_NAME) $(LINUX_ARM64_FULL_IMAGE_NAME)
            if [ $? -ne 0 ]; then
              echo "Error: Docker buildx imagetools create failed."
              exit 1
            fi
          retryCountOnTaskFailure: 1
          workingDirectory: $(Build.SourcesDirectory)/otelcollector/
          displayName: 'Build: build and push image to dev ACR'
        - bash: |
            echo "=== Verifying multi-arch manifest list ==="
            MANIFEST_VERBOSE=$(docker buildx imagetools inspect $(LINUX_FULL_IMAGE_NAME) --raw 2>&1)
            echo "$MANIFEST_VERBOSE"
            
            # Check if it's a manifest list by looking for manifests array
            HAS_MANIFESTS=$(echo "$MANIFEST_VERBOSE" | jq 'has("manifests")' -r)
            
            if [ "$HAS_MANIFESTS" != "true" ]; then
              echo "##vso[task.logissue type=error]ERROR: Expected manifest list but got single manifest. Multi-arch image should be a manifest list."
              exit 1
            fi
            echo "Manifest Type: MANIFEST LIST (multi-arch) "
            
            # Count the number of manifests
            MANIFEST_COUNT=$(echo "$MANIFEST_VERBOSE" | jq '.manifests | length')
            echo "Number of manifests: $MANIFEST_COUNT"
            
            if [ "$MANIFEST_COUNT" -lt 2 ]; then
              echo "##vso[task.logissue type=error]ERROR: Expected at least 2 architectures but found $MANIFEST_COUNT"
              exit 1
            fi
            echo "Manifest count verified: $MANIFEST_COUNT architectures "
            
            # Extract architectures from manifest list
            ARCHS=$(echo "$MANIFEST_VERBOSE" | jq -r '.manifests[].platform.architecture' | sort | tr '\n' ' ')
            echo "Architectures found: $ARCHS"
            
            # Check for amd64
            if ! echo "$ARCHS" | grep -q "amd64"; then
              echo "##vso[task.logissue type=error]ERROR: Missing amd64 architecture in manifest list"
              exit 1
            fi
            echo "amd64 architecture found "
            
            # Check for arm64
            if ! echo "$ARCHS" | grep -q "arm64"; then
              echo "##vso[task.logissue type=error]ERROR: Missing arm64 architecture in manifest list"
              exit 1
            fi
            echo "arm64 architecture found "
            
            echo " Multi-arch manifest list verified successfully with amd64 and arm64 (total: $MANIFEST_COUNT architectures)"
          displayName: 'Build: verify multi-arch manifest list'
          condition: succeeded()
        - bash: |
            # Get the manifest using docker buildx imagetools inspect with raw output
            MANIFEST_RAW=$(docker buildx imagetools inspect $(LINUX_FULL_IMAGE_NAME) --raw)
            MEDIA_TYPE=$(echo "$MANIFEST_RAW" | jq -r '.mediaType')
            # Get digest from the image reference
            DIGEST=$(docker buildx imagetools inspect $(LINUX_FULL_IMAGE_NAME) 2>&1 | grep -oP 'Digest:\s+\K[^\s]+' | head -1)
            SIZE=$(echo "$MANIFEST_RAW" | jq -c '.' | wc -c)
            cat <<EOF >>$(Build.ArtifactStagingDirectory)/linux/payload.json
            {"targetArtifact":{"mediaType":$MEDIA_TYPE,"digest":$DIGEST,"size":$SIZE}}
            EOF
            echo "Contents of payload.json:"
            cat $(Build.ArtifactStagingDirectory)/linux/payload.json
          workingDirectory: $(Build.SourcesDirectory)/otelcollector/
          displayName: 'Build: Set values in payload.json for signing'
          condition: succeeded()
        - task: EsrpCodeSigning@5
          displayName: "ESRP CodeSigning for Prometheus Linux"
          inputs:
            ConnectedServiceName: 'ESRPServiceConnectionPrometheus'
            UseMSIAuthentication: true
            AppRegistrationClientId: 'bf21d5fe-78bd-45d2-b04d-c61f2e090c9a'
            AppRegistrationTenantId: '33e01921-4d64-4f8c-a055-5bdaffd5e33d'
            EsrpClientId: "73f8d5f9-b507-497f-b698-4ed00fcba5a3"
            AuthAKVName: 'ESRPPrometheusKVProd'
            AuthCertName: 'ESRPContainerImageSignCert'
            AuthSignCertName: 'ESRPReqPrometheusProdCert'
            FolderPath: '$(Build.ArtifactStagingDirectory)/linux/'
            Pattern: '*.json'
            signConfigType: 'inlineSignParams'
            inlineOperation: |
              [
                {
                    "keyCode": "CP-469451",
                    "operationSetCode": "NotaryCoseSign",
                    "parameters": [
                      {
                        "parameterName": "CoseFlags",
                        "parameterValue": "chainunprotected"
                      }
                    ],
                    "toolName": "sign",
                    "toolVersion": "1.0"
                }
              ]
            SessionTimeout: '60'
            MaxConcurrency: '50'
            MaxRetryAttempts: '5'
            PendingAnalysisWaitTimeoutMinutes: '5'
        - bash: |
            set -euxo pipefail
            curl -LO "https://github.com/oras-project/oras/releases/download/v1.0.0/oras_1.0.0_linux_amd64.tar.gz"
            mkdir -p oras-install/
            tar -zxf oras_1.0.0_*.tar.gz -C oras-install/
            sudo mv oras-install/oras /usr/local/bin/
            rm -rf oras_1.0.0_*.tar.gz oras-install/
            oras attach $(LINUX_FULL_IMAGE_NAME) \
              --artifact-type 'application/vnd.cncf.notary.signature' \
              ./payload.json:application/cose \
              -a "io.cncf.notary.x509chain.thumbprint#S256=[\"79E6A702361E1F60DAA84AEEC4CBF6F6420DE6BA\"]"
            oras attach $(LINUX_FULL_IMAGE_NAME) \
              --artifact-type 'application/vnd.microsoft.artifact.lifecycle' \
              --annotation "vnd.microsoft.artifact.lifecycle.end-of-life.date=$(date -u -d '-1 hour' +"%Y-%m-%dT%H:%M:%SZ")"
          workingDirectory: $(Build.ArtifactStagingDirectory)/linux/
          displayName: "ORAS Push Artifacts in $(Build.ArtifactStagingDirectory)/linux/"
          condition: succeeded()
        - bash: |
            curl -sfL https://raw.githubusercontent.com/aquasecurity/trivy/main/contrib/install.sh | sh -s -- -b /usr/local/bin
            export TRIVY_DB_REPOSITORY="ghcr.io/aquasecurity/trivy-db,public.ecr.aws/aquasecurity/trivy-db"
            export TRIVY_JAVA_DB_REPOSITORY="ghcr.io/aquasecurity/trivy-java-db,public.ecr.aws/aquasecurity/trivy-java-db"
            for image in $(LINUX_FULL_IMAGE_NAME) $(KUBE_STATE_METRICS_IMAGE) $(NODE_EXPORTER_IMAGE); do
              for i in {1..5}; do
                trivy image --exit-code 1 --ignore-unfixed --no-progress --severity HIGH,CRITICAL,MEDIUM $image > trivy_output.log 2>&1
                TRIVY_EXIT_CODE=$?
                if [ $TRIVY_EXIT_CODE -eq 0 ]; then
                  cat trivy_output.log
                  break
                fi
                if grep -q "TOOMANYREQUESTS" trivy_output.log; then
                  echo "Error: Too many requests to the Trivy server. Retrying ($i/5)"
                  sleep 5
                else
                  cat trivy_output.log
                  exit 1
                fi
              done
              if [ $TRIVY_EXIT_CODE -ne 0 ]; then
                echo "Error: Trivy scan failed after 5 retries."
                exit 1
              fi
            done
          workingDirectory: $(Build.SourcesDirectory)
          displayName: "Build: run trivy scan"
        - task: CodeQL3000Finalize@0
          displayName: 'SDL: run codeql'
        - task: ComponentGovernanceComponentDetection@0
          displayName: "SDL: run component governance"
          inputs:
            scanType: 'Register'
            verbosity: 'Verbose'
            dockerImagesToScan: '$(LINUX_FULL_IMAGE_NAME)'
            alertWarningLevel: 'High'
            sourceScanPath: '$(Build.SourcesDirectory)/otelcollector'
            ignoreDirectories: '$(Build.SourcesDirectory)/mixins,$(Build.SourcesDirectory)/tools,$(Build.SourcesDirectory)/otelcollector/react'
        - task: SdtReport@2
          displayName: 'SDL: generate report'
          inputs:
            GdnExportAllTools: false
            GdnExportGdnToolBinSkim: true
            GdnExportGdnToolBinSkimSeverity: 'Note'
            GdnExportGdnToolGosec: true
            GdnExportGdnToolGosecSeverity: 'Note'
            GdnExportGdnToolSemmle: true
            GdnExportGdnToolSemmleSeverity: 'Note'
        - task: PublishSecurityAnalysisLogs@3
          displayName: 'SDL: publish report'
          inputs:
            ArtifactName: 'CodeAnalysisLogs'
            ArtifactType: 'Container'
            PublishProcessedResults: true
            AllTools: true
            ToolLogsNotFoundAction: 'Standard'
        - task: PostAnalysis@2
          displayName: 'SDL: Post-Build Analysis'
          inputs:
            GdnBreakAllTools: false
            GdnBreakGdnToolBinSkim: true
            GdnBreakGdnToolBinSkimSeverity: 'Warning'
            GdnBreakGdnToolGosec: true
            GdnBreakGdnToolGosecSeverity: 'Warning'
            GdnBreakGdnToolSemmle: true
            GdnBreakGdnToolSemmleSeverity: 'Warning'
      - job: Linux_CCP_Prometheus_Collector
        displayName: "Build: linux CCP prometheus-collector image"
        pool:
          name: Azure-Pipelines-CI-Test-EO
          image: ci-1es-managed-ubuntu-2204
          os: linux
        dependsOn: Image_Tags_and_Ev2_Artifacts
        variables:
          LINUX_CCP_FULL_IMAGE_NAME: $[ dependencies.Image_Tags_and_Ev2_Artifacts.outputs['setup.LINUX_CCP_FULL_IMAGE_NAME'] ]
          DOCKER_BUILDKIT: 1
        templateContext:
          outputs:
          - output: pipelineArtifact
            displayName: 'Ev2: Publish image artifacts'
            condition: and(succeeded(), and(eq(variables.IS_PR, false), eq(variables.IS_MAIN_BRANCH, true)))
            targetPath: '$(Build.ArtifactStagingDirectory)/linuxccp'
            artifactName: linuxccp-drop
        steps:
        - checkout: self
          submodules: true
        - task: CodeQL3000Init@0
          displayName: 'SDL: init codeql'
        - bash: |
            set -e
            wget -q https://go.dev/dl/go$(GOLANG_VERSION).linux-amd64.tar.gz
            sudo rm -rf /usr/local/go
            sudo tar -C /usr/local -xzf go$(GOLANG_VERSION).linux-amd64.tar.gz
            echo "##vso[task.prependpath]/usr/local/go/bin"
            go version
          displayName: "Build: install golang $(GOLANG_VERSION)"
        - bash: |
            mkdir -p $(Build.ArtifactStagingDirectory)/linuxccp
            # Necessary due to necessary due to https://stackoverflow.com/questions/60080264/docker-cannot-build-multi-platform-images-with-docker-buildx
            sudo apt-get update && sudo apt-get -y install qemu binfmt-support qemu-user-static
            docker system prune --all -f
            docker images -q --filter "dangling=true" | xargs docker rmi
            docker login containerinsightsprod.azurecr.io -u $(ACR_USERNAME) -p $(ACR_PASSWORD)
            docker run --rm --privileged multiarch/qemu-user-static --reset -p yes
            docker pull mcr.microsoft.com/azuremonitor/containerinsights/cidev/prometheus-collector/images:buildx-stable-1
            docker buildx create --name dockerbuilder --driver docker-container --driver-opt image=mcr.microsoft.com/azuremonitor/containerinsights/cidev/prometheus-collector/images:buildx-stable-1 --use 
            docker buildx inspect --bootstrap
            docker buildx build . --platform=linux/amd64,linux/arm64 --file ./build/linux/ccp/Dockerfile -t $(LINUX_CCP_FULL_IMAGE_NAME) --build-arg "GOLANG_VERSION=$(GOLANG_VERSION)" --metadata-file $(Build.ArtifactStagingDirectory)/linuxccp/metadata.json --push # --cache-to type=registry,ref=$(ACR_REGISTRY)$(ACR_REPOSITORY)/cache:prometheuscollectorccp,mode=max --cache-from type=registry,ref=$(ACR_REGISTRY)$(ACR_REPOSITORY)/cache:prometheuscollectorccp
            if [ $? -ne 0 ]; then
              echo "Error: Docker build failed."
              exit 1
            fi
            docker pull $(LINUX_CCP_FULL_IMAGE_NAME)
            docker system prune --all -f
          retryCountOnTaskFailure: 1
          workingDirectory: $(Build.SourcesDirectory)/otelcollector/
          displayName: "Build: build and push CCP image to dev ACR"
        - bash: |
            MEDIA_TYPE=$(docker manifest inspect -v $(LINUX_CCP_FULL_IMAGE_NAME) | jq '.Descriptor.mediaType')
            DIGEST=$(docker manifest inspect -v $(LINUX_CCP_FULL_IMAGE_NAME) | jq '.Descriptor.digest')
            SIZE=$(docker manifest inspect -v $(LINUX_CCP_FULL_IMAGE_NAME) | jq '.Descriptor.size')
            cat <<EOF >>$(Build.ArtifactStagingDirectory)/linuxccp/payload.json
            {"targetArtifact":{"mediaType":$MEDIA_TYPE,"digest":$DIGEST,"size":$SIZE}}
            EOF
          workingDirectory: $(Build.SourcesDirectory)/otelcollector/
          displayName: "Build: Set values in payload.json for signing"
          condition: succeeded()
        - task: EsrpCodeSigning@5
          displayName: "ESRP CodeSigning for Prometheus Linux CCP"
          inputs:
            ConnectedServiceName: "ESRPServiceConnectionPrometheus"
            UseMSIAuthentication: true
            AppRegistrationClientId: 'bf21d5fe-78bd-45d2-b04d-c61f2e090c9a'
            AppRegistrationTenantId: '33e01921-4d64-4f8c-a055-5bdaffd5e33d'
            EsrpClientId: "73f8d5f9-b507-497f-b698-4ed00fcba5a3"
            AuthAKVName: 'ESRPPrometheusKVProd'
            AuthCertName: 'ESRPContainerImageSignCert'
            AuthSignCertName: 'ESRPReqPrometheusProdCert'
            FolderPath: $(Build.ArtifactStagingDirectory)/linuxccp/
            Pattern: "*.json"
            signConfigType: inlineSignParams
            inlineOperation: |
              [
                {
                    "keyCode": "CP-469451",
                    "operationSetCode": "NotaryCoseSign",
                    "parameters": [
                      {
                        "parameterName": "CoseFlags",
                        "parameterValue": "chainunprotected"
                      }
                    ],
                    "toolName": "sign",
                    "toolVersion": "1.0"
                }
              ]
            SessionTimeout: '60'
            MaxConcurrency: '50'
            MaxRetryAttempts: '5'
            PendingAnalysisWaitTimeoutMinutes: '5'
        - bash: |
            set -euxo pipefail
            curl -LO "https://github.com/oras-project/oras/releases/download/v1.0.0/oras_1.0.0_linux_amd64.tar.gz"
            mkdir -p oras-install/
            tar -zxf oras_1.0.0_*.tar.gz -C oras-install/
            sudo mv oras-install/oras /usr/local/bin/
            rm -rf oras_1.0.0_*.tar.gz oras-install/
            oras attach $(LINUX_CCP_FULL_IMAGE_NAME) \
              --artifact-type 'application/vnd.cncf.notary.signature' \
              ./payload.json:application/cose \
              -a "io.cncf.notary.x509chain.thumbprint#S256=[\"79E6A702361E1F60DAA84AEEC4CBF6F6420DE6BA\"]"
            oras attach $(LINUX_CCP_FULL_IMAGE_NAME) \
              --artifact-type 'application/vnd.microsoft.artifact.lifecycle' \
              --annotation "vnd.microsoft.artifact.lifecycle.end-of-life.date=$(date -u -d '-1 hour' +"%Y-%m-%dT%H:%M:%SZ")"            
          workingDirectory: $(Build.ArtifactStagingDirectory)/linuxccp/
          displayName: "ORAS Push Artifacts in $(Build.ArtifactStagingDirectory)/linuxccp/"
          condition: succeeded()
        - bash: |
            curl -sfL https://raw.githubusercontent.com/aquasecurity/trivy/main/contrib/install.sh | sh -s -- -b /usr/local/bin
            export TRIVY_DB_REPOSITORY="ghcr.io/aquasecurity/trivy-db,public.ecr.aws/aquasecurity/trivy-db"
            export TRIVY_JAVA_DB_REPOSITORY="ghcr.io/aquasecurity/trivy-java-db,public.ecr.aws/aquasecurity/trivy-java-db"
            for i in {1..5}; do
              trivy image --exit-code 1 --ignore-unfixed --no-progress --severity HIGH,CRITICAL,MEDIUM $(LINUX_CCP_FULL_IMAGE_NAME) > trivy_output.log 2>&1
              TRIVY_EXIT_CODE=$?
              if [ $TRIVY_EXIT_CODE -eq 0 ]; then
                cat trivy_output.log
                break
              fi
              if grep -q "TOOMANYREQUESTS" trivy_output.log; then
                echo "Error: Too many requests to the Trivy server. Retrying ($i/5)"
                sleep 5
              else
                cat trivy_output.log
                exit 1
              fi
            done
            if [ $TRIVY_EXIT_CODE -ne 0 ]; then
              echo "Error: Trivy scan failed after 5 retries."
              exit 1
            fi
          workingDirectory: $(Build.SourcesDirectory)
          displayName: "Build: run trivy scan"
        - task: CodeQL3000Finalize@0
          displayName: 'SDL: run codeql'
        - task: ComponentGovernanceComponentDetection@0
          displayName: "SDL: run component governance"
          inputs:
            scanType: 'Register'
            verbosity: 'Verbose'
            dockerImagesToScan: '$(LINUX_CCP_FULL_IMAGE_NAME)'
            alertWarningLevel: 'High'
            sourceScanPath: '$(Build.SourcesDirectory)/otelcollector'
            ignoreDirectories: '$(Build.SourcesDirectory)/mixins,$(Build.SourcesDirectory)/tools,$(Build.SourcesDirectory)/otelcollector/react'
        - task: AzureArtifacts.manifest-generator-task.manifest-generator-task.ManifestGeneratorTask@0
          displayName: "Ev2: Generate image artifacts"
          condition: and(succeeded(), and(eq(variables.IS_PR, false), eq(variables.IS_MAIN_BRANCH, true)))
          inputs:
            BuildDropPath: '$(Build.ArtifactStagingDirectory)/linuxccp'
            DockerImagesToScan: '$(LINUX_CCP_FULL_IMAGE_NAME)'
        - task: SdtReport@2
          displayName: 'SDL: generate report'
          inputs:
            GdnExportAllTools: false
            GdnExportGdnToolBinSkim: true
            GdnExportGdnToolBinSkimSeverity: 'Note'
            GdnExportGdnToolGosec: true
            GdnExportGdnToolGosecSeverity: 'Note'
            GdnExportGdnToolSemmle: true
            GdnExportGdnToolSemmleSeverity: 'Note'
        - task: PublishSecurityAnalysisLogs@3
          displayName: 'SDL: publish report'
          inputs:
            ArtifactName: 'CodeAnalysisLogs'
            ArtifactType: 'Container'
            PublishProcessedResults: true
            AllTools: true
            ToolLogsNotFoundAction: 'Standard'
        - task: PostAnalysis@2
          displayName: 'SDL: Post-Build Analysis'
          inputs:
            GdnBreakAllTools: false
            GdnBreakGdnToolBinSkim: true
            GdnBreakGdnToolBinSkimSeverity: 'Warning'
            GdnBreakGdnToolGosec: true
            GdnBreakGdnToolGosecSeverity: 'Warning'
            GdnBreakGdnToolSemmle: true
            GdnBreakGdnToolSemmleSeverity: 'Warning'
      - job: Linux_Target_Allocator_AMD64
        displayName: "Build: AMD64 target allocator image"
        pool:
          name: Azure-Pipelines-CI-Test-EO
          image: ci-1es-managed-ubuntu-2204
          os: linux
        dependsOn: Image_Tags_and_Ev2_Artifacts
        variables:
          TARGET_ALLOCATOR_FULL_IMAGE_NAME: $[ dependencies.Image_Tags_and_Ev2_Artifacts.outputs['setup.TARGET_ALLOCATOR_FULL_IMAGE_NAME'] ]
          TARGET_ALLOCATOR_AMD64_FULL_IMAGE_NAME: $[ dependencies.Image_Tags_and_Ev2_Artifacts.outputs['setup.TARGET_ALLOCATOR_AMD64_FULL_IMAGE_NAME'] ]
          DOCKER_BUILDKIT: 1
          skipComponentGovernanceDetection: true
        steps:
        - checkout: self
          persistCredentials: true
        - bash: |
            set -e
            wget -q https://go.dev/dl/go$(GOLANG_VERSION).linux-amd64.tar.gz
            sudo rm -rf /usr/local/go
            sudo tar -C /usr/local -xzf go$(GOLANG_VERSION).linux-amd64.tar.gz
            echo "##vso[task.prependpath]/usr/local/go/bin"
            go version
          displayName: "Build: install golang $(GOLANG_VERSION)"
        - bash: |
            mkdir -p $(Build.ArtifactStagingDirectory)/targetallocator
            docker login containerinsightsprod.azurecr.io -u $(ACR_USERNAME) -p $(ACR_PASSWORD)

            echo "=== Docker Version Info (AMD64 Agent) ==="
            sudo docker version
            echo "==========================================="

            docker build . --file Dockerfile -t $(TARGET_ALLOCATOR_AMD64_FULL_IMAGE_NAME) --build-arg "GOLANG_VERSION=$(GOLANG_VERSION)" --metadata-file $(Build.ArtifactStagingDirectory)/targetallocator/metadata.json --push
            if [ $? -ne 0 ]; then
              echo "Error: Docker build failed."
              exit 1
            fi
          retryCountOnTaskFailure: 1
          workingDirectory: $(Build.SourcesDirectory)/otelcollector/otel-allocator
          displayName: "Build: build and push target allocator image to dev ACR"
          condition: succeeded()
      - job: Linux_Target_Allocator_ARM64
        displayName: "Build: ARM64 target allocator image"
        pool:
          name: Azure-Pipelines-ARM-CI-Test-EO
          os: linux
          hostArchitecture: Arm64
          image: ci-1es-managed-arm64-ubuntu--2204
        dependsOn: Image_Tags_and_Ev2_Artifacts
        variables:
          TARGET_ALLOCATOR_FULL_IMAGE_NAME: $[ dependencies.Image_Tags_and_Ev2_Artifacts.outputs['setup.TARGET_ALLOCATOR_FULL_IMAGE_NAME'] ]
          TARGET_ALLOCATOR_AMD64_FULL_IMAGE_NAME: $[ dependencies.Image_Tags_and_Ev2_Artifacts.outputs['setup.TARGET_ALLOCATOR_AMD64_FULL_IMAGE_NAME'] ]
          TARGET_ALLOCATOR_ARM64_FULL_IMAGE_NAME: $[ dependencies.Image_Tags_and_Ev2_Artifacts.outputs['setup.TARGET_ALLOCATOR_ARM64_FULL_IMAGE_NAME'] ]
          DOCKER_BUILDKIT: 1
          skipComponentGovernanceDetection: true
        steps:
        - checkout: self
          persistCredentials: true
        - bash: |
            set -e
            wget -q https://go.dev/dl/go$(GOLANG_VERSION).linux-arm64.tar.gz
            sudo rm -rf /usr/local/go
            sudo tar -C /usr/local -xzf go$(GOLANG_VERSION).linux-arm64.tar.gz
            export PATH="/usr/local/go/bin:${PATH}"
            echo "##vso[task.prependpath]/usr/local/go/bin"
            go version
          displayName: "Build: install golang $(GOLANG_VERSION)"
        - bash: |
            # Add Docker's official GPG key:
            # sudo apt-get update
            # sudo apt-get install ca-certificates curl -y
            # sudo install -m 0755 -d /etc/apt/keyrings
            # sudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc
            # sudo chmod a+r /etc/apt/keyrings/docker.asc
            # # Add the repository to Apt sources:
            # echo "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu $(. /etc/os-release && echo "${UBUNTU_CODENAME:-$VERSION_CODENAME}") stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
            # sudo apt-get update
            # sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin -y
            
            echo "=== Docker Version Info (ARM64 Agent) ==="
            sudo docker version
            echo "==========================================="

            mkdir -p $(Build.ArtifactStagingDirectory)/targetallocator
            sudo docker login containerinsightsprod.azurecr.io -u $(ACR_USERNAME) -p $(ACR_PASSWORD)
            sudo docker build . --file Dockerfile -t $(TARGET_ALLOCATOR_ARM64_FULL_IMAGE_NAME) --build-arg "GOLANG_VERSION=$(GOLANG_VERSION)" --metadata-file $(Build.ArtifactStagingDirectory)/targetallocator/metadata.json --push
            if [ $? -ne 0 ]; then
              echo "Error: Docker build failed."
              exit 1
            fi
          retryCountOnTaskFailure: 1
          workingDirectory: $(Build.SourcesDirectory)/otelcollector/otel-allocator
          displayName: "Build: build and push target allocator image to dev ACR"
          condition: succeeded()
      - job: Linux_Target_Allocator
        displayName: "Build: target allocator image"
        pool:
          name: Azure-Pipelines-CI-Test-EO
          image: ci-1es-managed-ubuntu-2204
          os: linux
        dependsOn:
        - Image_Tags_and_Ev2_Artifacts
        - Linux_Target_Allocator_ARM64
        - Linux_Target_Allocator_AMD64
        variables:
          TARGET_ALLOCATOR_FULL_IMAGE_NAME: $[ dependencies.Image_Tags_and_Ev2_Artifacts.outputs['setup.TARGET_ALLOCATOR_FULL_IMAGE_NAME'] ]
          TARGET_ALLOCATOR_AMD64_FULL_IMAGE_NAME: $[ dependencies.Image_Tags_and_Ev2_Artifacts.outputs['setup.TARGET_ALLOCATOR_AMD64_FULL_IMAGE_NAME'] ]
          TARGET_ALLOCATOR_ARM64_FULL_IMAGE_NAME: $[ dependencies.Image_Tags_and_Ev2_Artifacts.outputs['setup.TARGET_ALLOCATOR_ARM64_FULL_IMAGE_NAME'] ]
          DOCKER_BUILDKIT: 1
          skipComponentGovernanceDetection: true
        steps:
        - checkout: self
          persistCredentials: true
        - bash: |
            set -e
            wget -q https://go.dev/dl/go$(GOLANG_VERSION).linux-amd64.tar.gz
            sudo rm -rf /usr/local/go
            sudo tar -C /usr/local -xzf go$(GOLANG_VERSION).linux-amd64.tar.gz
            echo "##vso[task.prependpath]/usr/local/go/bin"
            go version
          displayName: "Build: install golang $(GOLANG_VERSION)"
        - bash: |
            mkdir -p $(Build.ArtifactStagingDirectory)/targetallocator
            docker login containerinsightsprod.azurecr.io -u $(ACR_USERNAME) -p $(ACR_PASSWORD)
            
            docker buildx imagetools create -t $(TARGET_ALLOCATOR_FULL_IMAGE_NAME) $(TARGET_ALLOCATOR_AMD64_FULL_IMAGE_NAME) $(TARGET_ALLOCATOR_ARM64_FULL_IMAGE_NAME)
            if [ $? -ne 0 ]; then
              echo "Error: Docker buildx imagetools create failed."
              exit 1
            fi

            # Get the manifest using docker buildx imagetools inspect with raw output
            MANIFEST_RAW=$(docker buildx imagetools inspect $(TARGET_ALLOCATOR_FULL_IMAGE_NAME) --raw)
            MEDIA_TYPE=$(echo "$MANIFEST_RAW" | jq -r '.mediaType')
            # Get digest from the image reference
            DIGEST=$(docker buildx imagetools inspect $(TARGET_ALLOCATOR_FULL_IMAGE_NAME) 2>&1 | grep -oP 'Digest:\s+\K[^\s]+' | head -1)
            SIZE=$(echo "$MANIFEST_RAW" | jq -c '.' | wc -c)
            cat <<EOF >>$(Build.ArtifactStagingDirectory)/targetallocator/payload.json
            {"targetArtifact":{"mediaType":$MEDIA_TYPE,"digest":$DIGEST,"size":$SIZE}}
            EOF
            echo "Contents of payload.json:"
            cat $(Build.ArtifactStagingDirectory)/targetallocator/payload.json
          workingDirectory: $(Build.SourcesDirectory)/otelcollector/otel-allocator
          displayName: "Build: build and push target allocator image to dev ACR"
          condition: succeeded()
        - bash: |
            echo "=== Verifying multi-arch manifest list ==="
            MANIFEST_VERBOSE=$(docker buildx imagetools inspect $(TARGET_ALLOCATOR_FULL_IMAGE_NAME) --raw 2>&1)
            echo "$MANIFEST_VERBOSE"
            
            # Check if it's a manifest list by looking for manifests array
            HAS_MANIFESTS=$(echo "$MANIFEST_VERBOSE" | jq 'has("manifests")' -r)
            
            if [ "$HAS_MANIFESTS" != "true" ]; then
              echo "##vso[task.logissue type=error]ERROR: Expected manifest list but got single manifest. Multi-arch image should be a manifest list."
              exit 1
            fi
            echo "Manifest Type: MANIFEST LIST (multi-arch) "
            
            # Count the number of manifests
            MANIFEST_COUNT=$(echo "$MANIFEST_VERBOSE" | jq '.manifests | length')
            echo "Number of manifests: $MANIFEST_COUNT"
            
            if [ "$MANIFEST_COUNT" -lt 2 ]; then
              echo "##vso[task.logissue type=error]ERROR: Expected at least 2 architectures but found $MANIFEST_COUNT"
              exit 1
            fi
            echo "Manifest count verified: $MANIFEST_COUNT architectures "
            
            # Extract architectures from manifest list
            ARCHS=$(echo "$MANIFEST_VERBOSE" | jq -r '.manifests[].platform.architecture' | sort | tr '\n' ' ')
            echo "Architectures found: $ARCHS"
            
            # Check for amd64
            if ! echo "$ARCHS" | grep -q "amd64"; then
              echo "##vso[task.logissue type=error]ERROR: Missing amd64 architecture in manifest list"
              exit 1
            fi
            echo "amd64 architecture found "
            
            # Check for arm64
            if ! echo "$ARCHS" | grep -q "arm64"; then
              echo "##vso[task.logissue type=error]ERROR: Missing arm64 architecture in manifest list"
              exit 1
            fi
            echo "arm64 architecture found "
            
            echo " Multi-arch manifest list verified successfully with amd64 and arm64 (total: $MANIFEST_COUNT architectures)"
          displayName: 'Build: verify multi-arch manifest list'
          condition: succeeded()
        - bash: |
            curl -sfL https://raw.githubusercontent.com/aquasecurity/trivy/main/contrib/install.sh | sh -s -- -b /usr/local/bin
            export TRIVY_DB_REPOSITORY="ghcr.io/aquasecurity/trivy-db,public.ecr.aws/aquasecurity/trivy-db"
            export TRIVY_JAVA_DB_REPOSITORY="ghcr.io/aquasecurity/trivy-java-db,public.ecr.aws/aquasecurity/trivy-java-db"
            for i in {1..5}; do
              trivy image --exit-code 1 --ignore-unfixed --no-progress --severity HIGH,CRITICAL,MEDIUM $(TARGET_ALLOCATOR_FULL_IMAGE_NAME) > trivy_output.log 2>&1
              TRIVY_EXIT_CODE=$?
              if [ $TRIVY_EXIT_CODE -eq 0 ]; then
                cat trivy_output.log
                break
              fi
              if grep -q "TOOMANYREQUESTS" trivy_output.log; then
                echo "Error: Too many requests to the Trivy server. Retrying ($i/5)"
                sleep 5
              else
                cat trivy_output.log
                exit 1
              fi
            done
            if [ $TRIVY_EXIT_CODE -ne 0 ]; then
              echo "Error: Trivy scan failed after 5 retries."
              exit 1
            fi
          workingDirectory: $(Build.SourcesDirectory)
          displayName: "Build: run trivy scan"
        - task: EsrpCodeSigning@5
          displayName: "ESRP CodeSigning for TargetAllocator"
          inputs:
            ConnectedServiceName: "ESRPServiceConnectionPrometheus"
            UseMSIAuthentication: true
            AppRegistrationClientId: 'bf21d5fe-78bd-45d2-b04d-c61f2e090c9a'
            AppRegistrationTenantId: '33e01921-4d64-4f8c-a055-5bdaffd5e33d'
            EsrpClientId: "73f8d5f9-b507-497f-b698-4ed00fcba5a3"
            AuthAKVName: 'ESRPPrometheusKVProd'
            AuthCertName: 'ESRPContainerImageSignCert'
            AuthSignCertName: 'ESRPReqPrometheusProdCert'
            FolderPath: $(Build.ArtifactStagingDirectory)/targetallocator/
            Pattern: "*.json"
            signConfigType: inlineSignParams
            inlineOperation: |
              [
                {
                    "keyCode": "CP-469451",
                    "operationSetCode": "NotaryCoseSign",
                    "parameters": [
                      {
                        "parameterName": "CoseFlags",
                        "parameterValue": "chainunprotected"
                      }
                    ],
                    "toolName": "sign",
                    "toolVersion": "1.0"
                }
              ]
            SessionTimeout: '60'
            MaxConcurrency: '50'
            MaxRetryAttempts: '5'
            PendingAnalysisWaitTimeoutMinutes: '5'
        - bash: |
            set -euxo pipefail
            curl -LO "https://github.com/oras-project/oras/releases/download/v1.0.0/oras_1.0.0_linux_amd64.tar.gz"
            mkdir -p oras-install/
            tar -zxf oras_1.0.0_*.tar.gz -C oras-install/
            sudo mv oras-install/oras /usr/local/bin/
            rm -rf oras_1.0.0_*.tar.gz oras-install/
            oras attach $(TARGET_ALLOCATOR_FULL_IMAGE_NAME) \
              --artifact-type 'application/vnd.cncf.notary.signature' \
              ./payload.json:application/cose \
              -a "io.cncf.notary.x509chain.thumbprint#S256=[\"79E6A702361E1F60DAA84AEEC4CBF6F6420DE6BA\"]"
            oras attach $(TARGET_ALLOCATOR_FULL_IMAGE_NAME) \
              --artifact-type 'application/vnd.microsoft.artifact.lifecycle' \
              --annotation "vnd.microsoft.artifact.lifecycle.end-of-life.date=$(date -u -d '-1 hour' +"%Y-%m-%dT%H:%M:%SZ")"                
          workingDirectory: $(Build.ArtifactStagingDirectory)/targetallocator/
          displayName: "ORAS Push Artifacts in $(Build.ArtifactStagingDirectory)/targetallocator/"
          condition: succeeded()
      - job: Linux_Config_Reader
        displayName: "Build: config reader image"
        pool:
          name: Azure-Pipelines-CI-Test-EO
          image: ci-1es-managed-ubuntu-2204
          os: linux
        dependsOn: Image_Tags_and_Ev2_Artifacts
        variables:
          LINUX_CONFIG_READER_FULL_IMAGE_NAME: $[ dependencies.Image_Tags_and_Ev2_Artifacts.outputs['setup.LINUX_CONFIG_READER_FULL_IMAGE_NAME'] ]
          DOCKER_BUILDKIT: 1
          skipComponentGovernanceDetection: true
        steps:
        - bash: |
            set -e
            wget -q https://go.dev/dl/go$(GOLANG_VERSION).linux-amd64.tar.gz
            sudo rm -rf /usr/local/go
            sudo tar -C /usr/local -xzf go$(GOLANG_VERSION).linux-amd64.tar.gz
            echo "##vso[task.prependpath]/usr/local/go/bin"
            go version
          displayName: "Build: install golang $(GOLANG_VERSION)"
        - bash: |
            mkdir -p $(Build.ArtifactStagingDirectory)/linuxcfgreader
            # Necessary due to necessary due to https://stackoverflow.com/questions/60080264/docker-cannot-build-multi-platform-images-with-docker-buildx
            sudo apt-get update && sudo apt-get -y install qemu binfmt-support qemu-user-static
            docker run --rm --privileged multiarch/qemu-user-static --reset -p yes
            docker system prune --all -f
            docker pull mcr.microsoft.com/azuremonitor/containerinsights/cidev/prometheus-collector/images:buildx-stable-1
            docker buildx create --name dockerbuilder --driver docker-container --driver-opt image=mcr.microsoft.com/azuremonitor/containerinsights/cidev/prometheus-collector/images:buildx-stable-1 --use 
            docker buildx inspect --bootstrap
            docker login containerinsightsprod.azurecr.io -u $(ACR_USERNAME) -p $(ACR_PASSWORD)
            docker buildx build . --platform=linux/amd64,linux/arm64 --file ./build/linux/configuration-reader/Dockerfile -t $(LINUX_CONFIG_READER_FULL_IMAGE_NAME) --build-arg "GOLANG_VERSION=$(GOLANG_VERSION)" --metadata-file $(Build.ArtifactStagingDirectory)/linux/configuration-reader/metadata.json --push # --cache-to type=registry,ref=$(ACR_REGISTRY)$(ACR_REPOSITORY)/cache:cfg,mode=max --cache-from type=registry,ref=$(ACR_REGISTRY)$(ACR_REPOSITORY)/cache:cfg
            docker pull $(LINUX_CONFIG_READER_FULL_IMAGE_NAME)
            MEDIA_TYPE=$(docker manifest inspect -v $(LINUX_CONFIG_READER_FULL_IMAGE_NAME) | jq '.Descriptor.mediaType')
            DIGEST=$(docker manifest inspect -v $(LINUX_CONFIG_READER_FULL_IMAGE_NAME) | jq '.Descriptor.digest')
            SIZE=$(docker manifest inspect -v $(LINUX_CONFIG_READER_FULL_IMAGE_NAME) | jq '.Descriptor.size')
            cat <<EOF >>$(Build.ArtifactStagingDirectory)/linuxcfgreader/payload.json
            {"targetArtifact":{"mediaType":$MEDIA_TYPE,"digest":$DIGEST,"size":$SIZE}}
            EOF
          retryCountOnTaskFailure: 1
          workingDirectory: $(Build.SourcesDirectory)/otelcollector/
          displayName: "Build: build and push configuration reader image to dev ACR"
          condition: succeeded()
        - bash: |
            curl -sfL https://raw.githubusercontent.com/aquasecurity/trivy/main/contrib/install.sh | sh -s -- -b /usr/local/bin
            export TRIVY_DB_REPOSITORY="ghcr.io/aquasecurity/trivy-db,public.ecr.aws/aquasecurity/trivy-db"
            export TRIVY_JAVA_DB_REPOSITORY="ghcr.io/aquasecurity/trivy-java-db,public.ecr.aws/aquasecurity/trivy-java-db"
            for i in {1..5}; do
              trivy image --exit-code 1 --ignore-unfixed --no-progress --severity HIGH,CRITICAL,MEDIUM $(LINUX_CONFIG_READER_FULL_IMAGE_NAME) > trivy_output.log 2>&1
              TRIVY_EXIT_CODE=$?
              if [ $TRIVY_EXIT_CODE -eq 0 ]; then
                cat trivy_output.log
                break
              fi
              if grep -q "TOOMANYREQUESTS" trivy_output.log; then
                echo "Error: Too many requests to the Trivy server. Retrying ($i/5)"
                sleep 5
              else
                cat trivy_output.log
                exit 1
              fi
            done
            if [ $TRIVY_EXIT_CODE -ne 0 ]; then
              echo "Error: Trivy scan failed after 5 retries."
              exit 1
            fi
          workingDirectory: $(Build.SourcesDirectory)
          displayName: "Build: run trivy scan"
        - task: EsrpCodeSigning@5
          displayName: "ESRP CodeSigning for Config Reader"
          inputs:
            ConnectedServiceName: "ESRPServiceConnectionPrometheus"
            UseMSIAuthentication: true
            AppRegistrationClientId: 'bf21d5fe-78bd-45d2-b04d-c61f2e090c9a'
            AppRegistrationTenantId: '33e01921-4d64-4f8c-a055-5bdaffd5e33d'
            EsrpClientId: "73f8d5f9-b507-497f-b698-4ed00fcba5a3"
            AuthAKVName: 'ESRPPrometheusKVProd'
            AuthCertName: 'ESRPContainerImageSignCert'
            AuthSignCertName: 'ESRPReqPrometheusProdCert'
            FolderPath: $(Build.ArtifactStagingDirectory)/linuxcfgreader/
            Pattern: "*.json"
            signConfigType: inlineSignParams
            inlineOperation: |
              [
                {
                    "keyCode": "CP-469451",
                    "operationSetCode": "NotaryCoseSign",
                    "parameters": [
                      {
                        "parameterName": "CoseFlags",
                        "parameterValue": "chainunprotected"
                      }
                    ],
                    "toolName": "sign",
                    "toolVersion": "1.0"
                }
              ]
            SessionTimeout: '60'
            MaxConcurrency: '50'
            MaxRetryAttempts: '5'
            PendingAnalysisWaitTimeoutMinutes: '5'
        - bash: |
            set -euxo pipefail
            curl -LO "https://github.com/oras-project/oras/releases/download/v1.0.0/oras_1.0.0_linux_amd64.tar.gz"
            mkdir -p oras-install/
            tar -zxf oras_1.0.0_*.tar.gz -C oras-install/
            sudo mv oras-install/oras /usr/local/bin/
            rm -rf oras_1.0.0_*.tar.gz oras-install/
            oras attach $(LINUX_CONFIG_READER_FULL_IMAGE_NAME) \
              --artifact-type 'application/vnd.cncf.notary.signature' \
              ./payload.json:application/cose \
              -a "io.cncf.notary.x509chain.thumbprint#S256=[\"79E6A702361E1F60DAA84AEEC4CBF6F6420DE6BA\"]"
            oras attach $(LINUX_CONFIG_READER_FULL_IMAGE_NAME) \
              --artifact-type 'application/vnd.microsoft.artifact.lifecycle' \
              --annotation "vnd.microsoft.artifact.lifecycle.end-of-life.date=$(date -u -d '-1 hour' +"%Y-%m-%dT%H:%M:%SZ")"              
          workingDirectory: $(Build.ArtifactStagingDirectory)/linuxcfgreader/
          displayName: "ORAS Push Artifacts in $(Build.ArtifactStagingDirectory)/linuxcfgreader/"
          condition: succeeded()
      - job: Windows2019_Prometheus_Collector
        displayName: "Build: windows 2019 prometheus-collector image"
        pool:
          name: Azure-Pipelines-CI-Test-EO
          image: ci-1es-managed-windows-2022
          os: windows
        timeoutInMinutes: 120
        dependsOn:
        - Image_Tags_and_Ev2_Artifacts
        variables:
          WINDOWS_FULL_IMAGE_NAME: $[ dependencies.Image_Tags_and_Ev2_Artifacts.outputs['setup.WINDOWS_FULL_IMAGE_NAME'] ]
          WINDOWS_2019_BASE_IMAGE_VERSION: $[ dependencies.Image_Tags_and_Ev2_Artifacts.outputs['setup.WINDOWS_2019_BASE_IMAGE_VERSION'] ]
          skipComponentGovernanceDetection: true
        condition: and(succeeded(), eq(variables.BUILD_WINDOWS, true))
        steps:
        - powershell: |
            $ErrorActionPreference = "Stop"
            Invoke-WebRequest -Uri "https://go.dev/dl/go$(GOLANG_VERSION).windows-amd64.zip" -OutFile "go.zip"
            Expand-Archive -Path "go.zip" -DestinationPath "C:\"
            Write-Host "##vso[task.prependpath]C:\go\bin"
            & "C:\go\bin\go.exe" version
          displayName: "Build: install golang $(GOLANG_VERSION)"
        - powershell: |
            ./makefile_windows.ps1 -PROMETHEUS_VERSION $(PROMETHEUS_VERSION)
          workingDirectory: $(Build.SourcesDirectory)/otelcollector/opentelemetry-collector-builder/
          displayName: "Build: build otelcollector and promconfigvalidator"
        - powershell: |
            $ErrorActionPreference = "Stop"
            Invoke-WebRequest -Uri "https://go.dev/dl/go$(FLUENTBIT_GOLANG_VERSION).windows-amd64.zip" -OutFile "go-fluentbit.zip"
            Expand-Archive -Path "go-fluentbit.zip" -DestinationPath "C:\go-fluentbit" -Force
            Write-Host "##vso[task.prependpath]C:\go-fluentbit\go\bin"
            & "C:\go-fluentbit\go\bin\go.exe" version
          displayName: "Build: install fluent-bit golang $(FLUENTBIT_GOLANG_VERSION)"
        - powershell: |
            ./makefile_windows.ps1
          workingDirectory: $(Build.SourcesDirectory)/otelcollector/fluent-bit/src/
          displayName: "Build: build fluent-bit plugin"
        - powershell: |
            docker build . --isolation=hyperv --file ./build/windows/Dockerfile -t $(WINDOWS_FULL_IMAGE_NAME)-$(WINDOWS_2019_BASE_IMAGE_VERSION)-unsigned --build-arg WINDOWS_VERSION=$(WINDOWS_2019_BASE_IMAGE_VERSION)
          workingDirectory: $(Build.SourcesDirectory)/otelcollector/
          displayName: "Build: build WS2019 image"
          retryCountOnTaskFailure: 2
        - task: PowerShell@2
          displayName: Extract files to sign
          inputs:
            targetType: 'inline'
            script: |
              echo "Creating docker container"
              docker create --name signingContainer $(WINDOWS_FULL_IMAGE_NAME)-$(WINDOWS_2019_BASE_IMAGE_VERSION)-unsigned
              echo "Creating fist party directory"
              mkdir -p $(Build.ArtifactStagingDirectory)/fpSigning
              cd $(Build.ArtifactStagingDirectory)/fpSigning
              echo "Extract prometheusui"
              docker cp signingContainer:C:\opt\microsoft\otelcollector\prometheusui.exe .
              echo "Extract main"
              docker cp signingContainer:C:\opt\microsoft\main.exe .
              echo "Extract OtelCollector"
              docker cp signingContainer:C:\opt\microsoft\otelcollector\otelcollector.exe .
              echo "Creating OSS directory"
              mkdir -p $(Build.ArtifactStagingDirectory)/ossSigning
              cd $(Build.ArtifactStagingDirectory)/ossSigning
              echo "Extract fluent-bit"
              docker cp signingContainer:C:\opt\fluent-bit .
              echo "Extract Ruby"
              docker cp signingContainer:C:\ruby26 .
              echo "Extract promconfigvalidator"
              docker cp signingContainer:C:\opt\promconfigvalidator.exe .
              echo "Removing container"
              docker rm signingContainer
              echo "List ArtifactStagingDirectory"
              ls $(Build.ArtifactStagingDirectory)
              ls .       
        - script: dir $(Build.ArtifactStagingDirectory)
          displayName: 'List files in Staging Directory'
        - task: EsrpCodeSigning@5
          inputs:
            ConnectedServiceName: 'ESRPServiceConnectionPrometheus'
            UseMSIAuthentication: true
            AppRegistrationClientId: 'bf21d5fe-78bd-45d2-b04d-c61f2e090c9a'
            AppRegistrationTenantId: '33e01921-4d64-4f8c-a055-5bdaffd5e33d'
            EsrpClientId: "73f8d5f9-b507-497f-b698-4ed00fcba5a3"
            AuthAKVName: 'ESRPPrometheusKVProd'
            AuthCertName: 'ESRPContainerImageSignCert'
            AuthSignCertName: 'ESRPReqPrometheusProdCert'
            FolderPath: '$(Build.ArtifactStagingDirectory)/fpSigning'
            Pattern: '*.dll,*.exe,*.so,*.ps1'
            signConfigType: 'inlineSignParams'
            inlineOperation: |
              [
                      {
                          "KeyCode" : "CP-230012",
                          "OperationCode" : "SigntoolSign",
                          "Parameters" : {
                              "OpusName" : "Microsoft",
                              "OpusInfo" : "http://www.microsoft.com",
                              "FileDigest" : "/fd \"SHA256\"",
                              "PageHash" : "/NPH",
                              "TimeStamp" : "/tr \"http://rfc3161.gtm.corp.microsoft.com/TSS/HttpTspServer\" /td sha256"
                          },
                          "ToolName" : "sign",
                          "ToolVersion" : "1.0"
                      },
                      {
                          "KeyCode" : "CP-230012",
                          "OperationCode" : "SigntoolVerify",
                          "Parameters" : {},
                          "ToolName" : "sign",
                          "ToolVersion" : "1.0"
                      }
                  ]
            SessionTimeout: '60'
            MaxConcurrency: '50'
            MaxRetryAttempts: '5'
          displayName: 'EsrpCodeSigning for first party binaries'
        - task: EsrpCodeSigning@5
          inputs:
            ConnectedServiceName: 'ESRPServiceConnectionPrometheus'
            UseMSIAuthentication: true
            AppRegistrationClientId: 'bf21d5fe-78bd-45d2-b04d-c61f2e090c9a'
            AppRegistrationTenantId: '33e01921-4d64-4f8c-a055-5bdaffd5e33d'
            EsrpClientId: "73f8d5f9-b507-497f-b698-4ed00fcba5a3"
            AuthAKVName: 'ESRPPrometheusKVProd'
            AuthCertName: 'ESRPContainerImageSignCert'
            AuthSignCertName: 'ESRPReqPrometheusProdCert'
            FolderPath: '$(Build.ArtifactStagingDirectory)/ossSigning'
            Pattern: '*.dll,*.exe,*.so'
            signConfigType: 'inlineSignParams'
            inlineOperation: |
              [
                      {
                          "KeyCode" : "CP-231522",
                          "OperationCode" : "SigntoolSign",
                          "Parameters" : {
                              "OpusName" : "Microsoft",
                              "OpusInfo" : "http://www.microsoft.com",
                              "Append" : "/as",
                              "FileDigest" : "/fd \"SHA256\"",
                              "PageHash" : "/NPH",
                              "TimeStamp" : "/tr \"http://rfc3161.gtm.corp.microsoft.com/TSS/HttpTspServer\" /td sha256"
                          },
                          "ToolName" : "sign",
                          "ToolVersion" : "1.0"
                      },
                      {
                          "KeyCode" : "CP-231522",
                          "OperationCode" : "SigntoolVerify",
                          "Parameters" : {},
                          "ToolName" : "sign",
                          "ToolVersion" : "1.0"
                      }
                  ]
            SessionTimeout: '60'
            MaxConcurrency: '50'
            MaxRetryAttempts: '5'
          displayName: 'EsrpCodeSigning for OSS binaries'
        - task: PowerShell@2
          displayName: Replace files in origin Image
          inputs:
            targetType: 'inline'
            script: |
              docker create --name pushContainer $(WINDOWS_FULL_IMAGE_NAME)-$(WINDOWS_2019_BASE_IMAGE_VERSION)-unsigned
              echo "Copy Signed binaries/folders back to docker image"
              docker cp $(Build.ArtifactStagingDirectory)/fpSigning/otelcollector.exe pushContainer:C:\opt\microsoft\otelcollector\otelcollector.exe
              docker cp $(Build.ArtifactStagingDirectory)/fpSigning/prometheusui.exe pushContainer:C:\opt\microsoft\otelcollector\prometheusui.exe
              docker cp $(Build.ArtifactStagingDirectory)/fpSigning/main.exe pushContainer:C:\opt\microsoft\main.exe
              docker cp $(Build.ArtifactStagingDirectory)/ossSigning/fluent-bit/. pushContainer:C:\opt\fluent-bit/
              docker cp $(Build.ArtifactStagingDirectory)/ossSigning/ruby26/. pushContainer:C:\ruby26/
              docker cp $(Build.ArtifactStagingDirectory)/ossSigning/promconfigvalidator.exe pushContainer:C:\opt\promconfigvalidator.exe
              docker commit pushContainer $(WINDOWS_FULL_IMAGE_NAME)-$(WINDOWS_2019_BASE_IMAGE_VERSION)
              docker rm pushContainer
        - powershell: |
            docker login containerinsightsprod.azurecr.io -u $(ACR_USERNAME) -p $(ACR_PASSWORD)
            docker push $(WINDOWS_FULL_IMAGE_NAME)-$(WINDOWS_2019_BASE_IMAGE_VERSION)
          displayName: "Build: push image to dev ACR"
      - job: Windows2022_Prometheus_Collector
        displayName: "Build: windows 2022 prometheus-collector image"
        pool:
          name: Azure-Pipelines-CI-Test-EO
          image: ci-1es-managed-windows-2022
          os: windows
        timeoutInMinutes: 120
        dependsOn:
        - Image_Tags_and_Ev2_Artifacts
        variables:
          WINDOWS_FULL_IMAGE_NAME: $[ dependencies.Image_Tags_and_Ev2_Artifacts.outputs['setup.WINDOWS_FULL_IMAGE_NAME'] ]
          WINDOWS_2022_BASE_IMAGE_VERSION: $[ dependencies.Image_Tags_and_Ev2_Artifacts.outputs['setup.WINDOWS_2022_BASE_IMAGE_VERSION'] ]
          skipComponentGovernanceDetection: true
        condition: and(succeeded(), eq(variables.BUILD_WINDOWS, true))
        steps:
        - powershell: |
            $ErrorActionPreference = "Stop"
            Invoke-WebRequest -Uri "https://go.dev/dl/go$(GOLANG_VERSION).windows-amd64.zip" -OutFile "go.zip"
            Expand-Archive -Path "go.zip" -DestinationPath "C:\"
            Write-Host "##vso[task.prependpath]C:\go\bin"
            & "C:\go\bin\go.exe" version
          displayName: "Build: install golang $(GOLANG_VERSION)"
        - powershell: |
            ./makefile_windows.ps1 -PROMETHEUS_VERSION $(PROMETHEUS_VERSION)
          workingDirectory: $(Build.SourcesDirectory)/otelcollector/opentelemetry-collector-builder/
          displayName: "Build: build otelcollector and promconfigvalidator"
        - powershell: |
            $ErrorActionPreference = "Stop"
            Invoke-WebRequest -Uri "https://go.dev/dl/go$(FLUENTBIT_GOLANG_VERSION).windows-amd64.zip" -OutFile "go-fluentbit.zip"
            Expand-Archive -Path "go-fluentbit.zip" -DestinationPath "C:\go-fluentbit" -Force
            Write-Host "##vso[task.prependpath]C:\go-fluentbit\go\bin"
            & "C:\go-fluentbit\go\bin\go.exe" version
          displayName: "Build: install fluent-bit golang $(FLUENTBIT_GOLANG_VERSION)"
        - powershell: |
            ./makefile_windows.ps1
          workingDirectory: $(Build.SourcesDirectory)/otelcollector/fluent-bit/src/
          displayName: "Build: build fluent-bit plugin"
        - powershell: |
            docker build . --isolation=hyperv --file ./build/windows/Dockerfile -t $(WINDOWS_FULL_IMAGE_NAME)-$(WINDOWS_2022_BASE_IMAGE_VERSION)-unsigned --build-arg WINDOWS_VERSION=$(WINDOWS_2022_BASE_IMAGE_VERSION)
          workingDirectory: $(Build.SourcesDirectory)/otelcollector/
          displayName: "Build: build WS2022 image"
          retryCountOnTaskFailure: 2
        - task: PowerShell@2
          displayName: Extract files to sign
          inputs:
            targetType: 'inline'
            script: |
              echo "Creating docker container"
              docker create --name signingContainer $(WINDOWS_FULL_IMAGE_NAME)-$(WINDOWS_2022_BASE_IMAGE_VERSION)-unsigned
              echo "Creating fist party directory"
              mkdir -p $(Build.ArtifactStagingDirectory)/fpSigning
              cd $(Build.ArtifactStagingDirectory)/fpSigning
              echo "Extract prometheusui"
              docker cp signingContainer:C:\opt\microsoft\otelcollector\prometheusui.exe .
              echo "Extract main"
              docker cp signingContainer:C:\opt\microsoft\main.exe .
              echo "Extract OtelCollector"
              docker cp signingContainer:C:\opt\microsoft\otelcollector\otelcollector.exe .
              echo "Creating OSS directory"
              mkdir -p $(Build.ArtifactStagingDirectory)/ossSigning
              cd $(Build.ArtifactStagingDirectory)/ossSigning
              echo "Extract fluent-bit"
              docker cp signingContainer:C:\opt\fluent-bit .
              echo "Extract Ruby"
              docker cp signingContainer:C:\ruby26 .
              echo "Extract promconfigvalidator"
              docker cp signingContainer:C:\opt\promconfigvalidator.exe .
              echo "Removing container"
              docker rm signingContainer
              echo "List ArtifactStagingDirectory"
              ls $(Build.ArtifactStagingDirectory)
              ls .       
        - script: dir $(Build.ArtifactStagingDirectory)
          displayName: 'List files in Staging Directory'
        - task: EsrpCodeSigning@5
          inputs:
            ConnectedServiceName: 'ESRPServiceConnectionPrometheus'
            UseMSIAuthentication: true
            AppRegistrationClientId: 'bf21d5fe-78bd-45d2-b04d-c61f2e090c9a'
            AppRegistrationTenantId: '33e01921-4d64-4f8c-a055-5bdaffd5e33d'
            EsrpClientId: "73f8d5f9-b507-497f-b698-4ed00fcba5a3"
            AuthAKVName: 'ESRPPrometheusKVProd'
            AuthCertName: 'ESRPContainerImageSignCert'
            AuthSignCertName: 'ESRPReqPrometheusProdCert'
            FolderPath: '$(Build.ArtifactStagingDirectory)/fpSigning'
            Pattern: '*.dll,*.exe,*.so,*.ps1'
            signConfigType: 'inlineSignParams'
            inlineOperation: |
              [
                      {
                          "KeyCode" : "CP-230012",
                          "OperationCode" : "SigntoolSign",
                          "Parameters" : {
                              "OpusName" : "Microsoft",
                              "OpusInfo" : "http://www.microsoft.com",
                              "FileDigest" : "/fd \"SHA256\"",
                              "PageHash" : "/NPH",
                              "TimeStamp" : "/tr \"http://rfc3161.gtm.corp.microsoft.com/TSS/HttpTspServer\" /td sha256"
                          },
                          "ToolName" : "sign",
                          "ToolVersion" : "1.0"
                      },
                      {
                          "KeyCode" : "CP-230012",
                          "OperationCode" : "SigntoolVerify",
                          "Parameters" : {},
                          "ToolName" : "sign",
                          "ToolVersion" : "1.0"
                      }
                  ]
            SessionTimeout: '60'
            MaxConcurrency: '50'
            MaxRetryAttempts: '5'
          displayName: 'EsrpCodeSigning for first party binaries'
        - task: EsrpCodeSigning@5
          inputs:
            ConnectedServiceName: 'ESRPServiceConnectionPrometheus'
            UseMSIAuthentication: true
            AppRegistrationClientId: 'bf21d5fe-78bd-45d2-b04d-c61f2e090c9a'
            AppRegistrationTenantId: '33e01921-4d64-4f8c-a055-5bdaffd5e33d'
            EsrpClientId: "73f8d5f9-b507-497f-b698-4ed00fcba5a3"
            AuthAKVName: 'ESRPPrometheusKVProd'
            AuthCertName: 'ESRPContainerImageSignCert'
            AuthSignCertName: 'ESRPReqPrometheusProdCert'
            FolderPath: '$(Build.ArtifactStagingDirectory)/ossSigning'
            Pattern: '*.dll,*.exe,*.so'
            signConfigType: 'inlineSignParams'
            inlineOperation: |
              [
                      {
                          "KeyCode" : "CP-231522",
                          "OperationCode" : "SigntoolSign",
                          "Parameters" : {
                              "OpusName" : "Microsoft",
                              "OpusInfo" : "http://www.microsoft.com",
                              "Append" : "/as",
                              "FileDigest" : "/fd \"SHA256\"",
                              "PageHash" : "/NPH",
                              "TimeStamp" : "/tr \"http://rfc3161.gtm.corp.microsoft.com/TSS/HttpTspServer\" /td sha256"
                          },
                          "ToolName" : "sign",
                          "ToolVersion" : "1.0"
                      },
                      {
                          "KeyCode" : "CP-231522",
                          "OperationCode" : "SigntoolVerify",
                          "Parameters" : {},
                          "ToolName" : "sign",
                          "ToolVersion" : "1.0"
                      }
                  ]
            SessionTimeout: '60'
            MaxConcurrency: '50'
            MaxRetryAttempts: '5'
          displayName: 'EsrpCodeSigning for OSS binaries'
        - task: PowerShell@2
          displayName: Replace files in origin Image
          inputs:
            targetType: 'inline'
            script: |
              docker create --name pushContainer $(WINDOWS_FULL_IMAGE_NAME)-$(WINDOWS_2022_BASE_IMAGE_VERSION)-unsigned
              echo "Copy Signed binaries/folders back to docker image"
              docker cp $(Build.ArtifactStagingDirectory)/fpSigning/otelcollector.exe pushContainer:C:\opt\microsoft\otelcollector\otelcollector.exe
              docker cp $(Build.ArtifactStagingDirectory)/fpSigning/prometheusui.exe pushContainer:C:\opt\microsoft\otelcollector\prometheusui.exe
              docker cp $(Build.ArtifactStagingDirectory)/fpSigning/main.exe pushContainer:C:\opt\microsoft\main.exe
              docker cp $(Build.ArtifactStagingDirectory)/ossSigning/fluent-bit/. pushContainer:C:\opt\fluent-bit/
              docker cp $(Build.ArtifactStagingDirectory)/ossSigning/ruby26/. pushContainer:C:\ruby26/
              docker cp $(Build.ArtifactStagingDirectory)/ossSigning/promconfigvalidator.exe pushContainer:C:\opt\promconfigvalidator.exe
              docker commit pushContainer $(WINDOWS_FULL_IMAGE_NAME)-$(WINDOWS_2022_BASE_IMAGE_VERSION)
              docker rm pushContainer
        - powershell: |
            docker login containerinsightsprod.azurecr.io -u $(ACR_USERNAME) -p $(ACR_PASSWORD)
            docker push $(WINDOWS_FULL_IMAGE_NAME)-$(WINDOWS_2022_BASE_IMAGE_VERSION)
          displayName: "Build: push image to dev ACR"
      - job: WindowsMultiArch_Prometheus_Collector
        displayName: "Build: windows multi-arch prometheus-collector image"
        pool:
          name: Azure-Pipelines-CI-Test-EO
          image: ci-1es-managed-windows-2022
          os: windows
        timeoutInMinutes: 120
        dependsOn:
        - Image_Tags_and_Ev2_Artifacts
        - Windows2019_Prometheus_Collector
        - Windows2022_Prometheus_Collector
        variables:
          WINDOWS_IMAGE_TAG: $[ dependencies.Image_Tags_and_Ev2_Artifacts.outputs['setup.WINDOWS_IMAGE_TAG'] ]
          WINDOWS_FULL_IMAGE_NAME: $[ dependencies.Image_Tags_and_Ev2_Artifacts.outputs['setup.WINDOWS_FULL_IMAGE_NAME'] ]
          WINDOWS_2019_BASE_IMAGE_VERSION: $[ dependencies.Image_Tags_and_Ev2_Artifacts.outputs['setup.WINDOWS_2019_BASE_IMAGE_VERSION'] ]
          WINDOWS_2022_BASE_IMAGE_VERSION: $[ dependencies.Image_Tags_and_Ev2_Artifacts.outputs['setup.WINDOWS_2022_BASE_IMAGE_VERSION'] ]
          skipComponentGovernanceDetection: true
        condition: and(succeeded(), eq(variables.BUILD_WINDOWS, true))
        templateContext:
          outputs:
          - output: pipelineArtifact
            displayName: 'Ev2: publish image artifacts'
            condition: and(succeeded(), and(eq(variables.IS_PR, false), eq(variables.IS_MAIN_BRANCH, true)))
            targetPath: '$(Build.ArtifactStagingDirectory)/windows'
            artifactName: windows-drop
        steps:
        - powershell: |
            $ErrorActionPreference = "Stop"
            Invoke-WebRequest -Uri "https://go.dev/dl/go$(GOLANG_VERSION).windows-amd64.zip" -OutFile "go.zip"
            Expand-Archive -Path "go.zip" -DestinationPath "C:\"
            Write-Host "##vso[task.prependpath]C:\go\bin"
            & "C:\go\bin\go.exe" version
          displayName: "Build: install golang $(GOLANG_VERSION)"
        - bash: |
            export ACR_REPOSITORY_VAR="$(ACR_REPOSITORY)"
            export ACR_REPOSITORY_WITHOUT_SLASH="${ACR_REPOSITORY_VAR:1}"
            export WINDOWS_2019_TAG="$(WINDOWS_IMAGE_TAG)-$(WINDOWS_2019_BASE_IMAGE_VERSION)"
            docker login containerinsightsprod.azurecr.io -u $(ACR_USERNAME) -p $(ACR_PASSWORD)
            docker pull $(WINDOWS_FULL_IMAGE_NAME)-$(WINDOWS_2019_BASE_IMAGE_VERSION)
            if [ $? -ne 0 ]; then
              echo "Failed to pull $(WINDOWS_FULL_IMAGE_NAME)-$(WINDOWS_2019_BASE_IMAGE_VERSION). Checking if MCR image is published."
              IMAGES_ARE_PUBLISHED=0
              for i in 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20
                do
                  output=$(curl -s https://$(MCR_REGISTRY)/v2$(MCR_REPOSITORY)/tags/list)
                  if (echo $output | grep $WINDOWS_2019_TAG)
                  then
                    echo "Images are published to mcr"
                    IMAGES_ARE_PUBLISHED=1
                    break
                  fi
                  sleep 30
                done
              if [ IMAGES_ARE_PUBLISHED -eq 0 ]; then
                echo "Images are not published to mcr within the timeout"
                exit 1
              fi
              az acr import --name $(ACR_REGISTRY) --source $(MCR_REGISTRY)$(MCR_REPOSITORY):$(IMAGE_TAG) --image $(ACR_REPOSITORY_WITHOUT_SLASH):$(WINDOWS_2019_TAG)
            fi
            export WINDOWS_2022_TAG="$(WINDOWS_IMAGE_TAG)-$(WINDOWS_2022_BASE_IMAGE_VERSION)"
            docker login containerinsightsprod.azurecr.io -u $(ACR_USERNAME) -p $(ACR_PASSWORD)
            docker pull $(WINDOWS_FULL_IMAGE_NAME)-$(WINDOWS_2022_BASE_IMAGE_VERSION)
            if [ $? -ne 0 ]; then
              echo "Failed to pull $(WINDOWS_FULL_IMAGE_NAME)-$(WINDOWS_2022_BASE_IMAGE_VERSION). Checking if MCR image is published."
              IMAGES_ARE_PUBLISHED=0
              for i in 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20
                do
                  output=$(curl -s https://$(MCR_REGISTRY)/v2$(MCR_REPOSITORY)/tags/list)
                  if (echo $output | grep $WINDOWS_2022_TAG)
                  then
                    echo "Images are published to mcr"
                    IMAGES_ARE_PUBLISHED=1
                    break
                  fi
                  sleep 30
                done
              if [ IMAGES_ARE_PUBLISHED -eq 0 ]; then
                echo "Images are not published to mcr within the timeout"
                exit 1
              fi
              az acr import --name $(ACR_REGISTRY) --source $(MCR_REGISTRY)$(MCR_REPOSITORY):$(IMAGE_TAG) --image $(ACR_REPOSITORY_WITHOUT_SLASH):$(WINDOWS_2022_TAG)
            fi
          displayName: "Build: ensure images are present in ACR"
          retryCountOnTaskFailure: 3
        - powershell: |
            New-Item -Path "$(Build.ArtifactStagingDirectory)" -Name "windows" -ItemType "directory"
            @{"image.name"="$(WINDOWS_FULL_IMAGE_NAME)"} | ConvertTo-Json -Compress | Out-File -Encoding ascii $(Build.ArtifactStagingDirectory)/windows/metadata.json
            docker login containerinsightsprod.azurecr.io -u $(ACR_USERNAME) -p $(ACR_PASSWORD)
            docker manifest create $(WINDOWS_FULL_IMAGE_NAME) $(WINDOWS_FULL_IMAGE_NAME)-$(WINDOWS_2019_BASE_IMAGE_VERSION) $(WINDOWS_FULL_IMAGE_NAME)-$(WINDOWS_2022_BASE_IMAGE_VERSION)
            docker manifest push $(WINDOWS_FULL_IMAGE_NAME)
          workingDirectory: $(Build.SourcesDirectory)/otelcollector/
          displayName: "Build: Windows multi-arch manifest"
        - task: AzureArtifacts.manifest-generator-task.manifest-generator-task.ManifestGeneratorTask@0
          condition: and(succeeded(), and(eq(variables.IS_PR, false), eq(variables.IS_MAIN_BRANCH, true)))
          displayName: "Ev2: generate image artifacts"
          inputs:
            BuildDropPath: '$(Build.ArtifactStagingDirectory)/windows'
            DockerImagesToScan: '$(WINDOWS_FULL_IMAGE_NAME)'
        - powershell: |
            $output = docker manifest inspect -v $(WINDOWS_FULL_IMAGE_NAME) | ConvertFrom-Json
            $firstManifest = $output[0]
            $MEDIA_TYPE = $firstManifest.Descriptor.mediaType
            $DIGEST = $firstManifest.Descriptor.digest
            $SIZE = $firstManifest.Descriptor.size
            $payload = @{
                targetArtifact = @{
                    mediaType = $MEDIA_TYPE
                    digest = $DIGEST
                    size = $SIZE
                }
            } | ConvertTo-Json
            $payload | Out-File -FilePath "$(Build.ArtifactStagingDirectory)/windows/payload.json"
          workingDirectory: $(Build.ArtifactStagingDirectory)/windows
          displayName: "Build the payload json file"
          condition: succeeded()
        - task: EsrpCodeSigning@5
          displayName: "ESRP CodeSigning for Windows Multi-Arch Prometheus"
          inputs:
            ConnectedServiceName: "ESRPServiceConnectionPrometheus"
            UseMSIAuthentication: true
            AppRegistrationClientId: 'bf21d5fe-78bd-45d2-b04d-c61f2e090c9a'
            AppRegistrationTenantId: '33e01921-4d64-4f8c-a055-5bdaffd5e33d'
            EsrpClientId: "73f8d5f9-b507-497f-b698-4ed00fcba5a3"
            AuthAKVName: 'ESRPPrometheusKVProd'
            AuthCertName: 'ESRPContainerImageSignCert'
            AuthSignCertName: 'ESRPReqPrometheusProdCert'
            FolderPath: $(Build.ArtifactStagingDirectory)/windows/
            Pattern: "*.json"
            signConfigType: inlineSignParams
            inlineOperation: |
              [
                {
                    "keyCode": "CP-469451",
                    "operationSetCode": "NotaryCoseSign",
                    "parameters": [
                      {
                        "parameterName": "CoseFlags",
                        "parameterValue": "chainunprotected"
                      }
                    ],
                    "toolName": "sign",
                    "toolVersion": "1.0"
                }
              ]
            SessionTimeout: '60'
            MaxConcurrency: '50'
            MaxRetryAttempts: '5'
            PendingAnalysisWaitTimeoutMinutes: '5'
        - powershell: |
            curl.exe -sLO  "https://github.com/oras-project/oras/releases/download/v1.0.0/oras_1.0.0_windows_amd64.zip"
            $currentDirectory = Get-Location
            Expand-Archive -Path $currentDirectory\oras_1.0.0_windows_amd64.zip -DestinationPath . -Force
            New-Item -ItemType Directory -Force -Path $env:USERPROFILE\bin
            Copy-Item -Path $currentDirectory\oras.exe -Destination "$env:USERPROFILE\bin\"
            $env:PATH = "$env:USERPROFILE\bin;$env:PATH"
            oras attach $(WINDOWS_FULL_IMAGE_NAME) --artifact-type application/vnd.cncf.notary.signature ./payload.json:application/cose -a io.cncf.notary.x509chain.thumbprint#S256=[\""79E6A702361E1F60DAA84AEEC4CBF6F6420DE6BA\""]
            oras attach $(WINDOWS_FULL_IMAGE_NAME) --artifact-type 'application/vnd.microsoft.artifact.lifecycle' --annotation "vnd.microsoft.artifact.lifecycle.end-of-life.date=$(powershell -Command "(Get-Date).AddHours(-1).ToString('yyyy-MM-ddTHH:mm:ssZ')")"          
          workingDirectory: $(Build.ArtifactStagingDirectory)/windows
          displayName: "Download, install Oras and run oras attach"
          condition: succeeded()
        - task: AntiMalware@4
          displayName: 'Run MpCmdRun.exe'
          inputs:
            InputType: Basic
            ScanType: CustomScan
            FileDirPath: '$(Build.ArtifactStagingDirectory)'
            DisableRemediation: false
            AcceptableOutdatedSignatureInHours: 48
            TreatAcceptableOutdatedSignatureAs: Warning
      - job: Arc_Helm_Chart
        displayName: "Package: Arc helm chart"
        pool:
          name: Azure-Pipelines-CI-Test-EO
          image: ci-1es-managed-ubuntu-2204
          os: linux
        dependsOn:
        - Image_Tags_and_Ev2_Artifacts
        - Linux_Prometheus_Collector
        variables:
          HELM_SEMVER: $[ dependencies.Image_Tags_and_Ev2_Artifacts.outputs['setup.SEMVER'] ]
          IMAGE_TAG: $[ dependencies.Image_Tags_and_Ev2_Artifacts.outputs['setup.SEMVER'] ]
          IMAGE_TAG_WINDOWS: $[ dependencies.Image_Tags_and_Ev2_Artifacts.outputs['setup.WINDOWS_IMAGE_TAG'] ]
          ARC_HELM_FULL_IMAGE_NAME: $[ dependencies.Image_Tags_and_Ev2_Artifacts.outputs['setup.ARC_HELM_FULL_IMAGE_NAME'] ]
          ARC_EXTENSION: true
          skipComponentGovernanceDetection: true
        templateContext:
          outputs:
          - output: pipelineArtifact
            displayName: 'Ev2: publish helm chart artifacts'
            condition: and(succeeded(), and(eq(variables.IS_PR, false), eq(variables.IS_MAIN_BRANCH, true)))
            targetPath: '$(Build.ArtifactStagingDirectory)/arc-chart'
            artifactName: arc-drop
        steps:
        - task: HelmInstaller@1
          displayName: 'Build: install Helm version'
          inputs:
            helmVersionToInstall: $(HELM_VERSION)
        - bash: |
            export HELM_CHART_NAME=$ARC_HELM_CHART_NAME
            envsubst < $(Build.SourcesDirectory)/otelcollector/deploy/addon-chart/azure-monitor-metrics-addon/Chart-template.yaml > $(Build.SourcesDirectory)/otelcollector/deploy/addon-chart/azure-monitor-metrics-addon/Chart.yaml && envsubst < $(Build.SourcesDirectory)/otelcollector/deploy/addon-chart/azure-monitor-metrics-addon/values-template.yaml > $(Build.SourcesDirectory)/otelcollector/deploy/addon-chart/azure-monitor-metrics-addon/values.yaml
            helm version
          displayName: "Build: substitute chart version in Chart.yaml and values.yaml"
        - bash: |
            helm dep update
          workingDirectory: $(Build.SourcesDirectory)/otelcollector/deploy/addon-chart/azure-monitor-metrics-addon
          displayName: "Build: update helm dependencies"
        - bash: |
            helm package ./azure-monitor-metrics-addon/
          workingDirectory: $(Build.SourcesDirectory)/otelcollector/deploy/addon-chart/
          displayName: "Build: package helm chart"
        - bash: |
            helm registry login containerinsightsprod.azurecr.io -u $(ACR_USERNAME) -p $(ACR_PASSWORD)
            helm push $(ARC_HELM_CHART_NAME)-$(HELM_SEMVER).tgz oci://$(ACR_REGISTRY)$(ACR_REPOSITORY_HELM)
            mkdir -p $(Build.ArtifactStagingDirectory)/arc-chart
            echo {\"image.name\":\"$(ARC_HELM_FULL_IMAGE_NAME)\"} > $(Build.ArtifactStagingDirectory)/arc-chart/metadata.json
          workingDirectory: $(Build.SourcesDirectory)/otelcollector/deploy/addon-chart/
          displayName: "Build: push helm chart to dev ACR"
      - job: Tag_Github_Commit
        displayName: "CI/CD: Tag commit with semver"
        pool:
          name: Azure-Pipelines-CI-Test-EO
          image: ci-1es-managed-ubuntu-2204
          os: linux
        dependsOn:
        - Image_Tags_and_Ev2_Artifacts
        - Arc_Helm_Chart
        - Linux_Prometheus_Collector
        - WindowsMultiArch_Prometheus_Collector
        condition: and(succeeded(), eq(variables.IS_MAIN_BRANCH, true))
        variables:
          HELM_SEMVER: $[ dependencies.Image_Tags_and_Ev2_Artifacts.outputs['setup.SEMVER'] ]
          skipComponentGovernanceDetection: true
        steps:
        - bash: |
            git config --global user.name "AzureDevOps Agent"
            git tag "v$(HELM_SEMVER)"
            git push origin "v$(HELM_SEMVER)"
          displayName: Tag commit with semver
    - stage: Deploy
      lockBehavior: sequential
      dependsOn: Build
      jobs:
      - deployment: Deploy_Chart_ARC
        templateContext:
            type: releaseJob
            isProduction: false
        displayName: "Deploy: Arc dev cluster"
        pool:
          name: Azure-Pipelines-CI-Test-EO
          image: ci-1es-managed-ubuntu-2204
          os: linux
        condition: and(succeeded(), and(and(eq(variables.IS_PR, false), eq(variables.IS_MAIN_BRANCH, true)), or(not(succeeded('Deploy_Chart_ARC')), eq(variables['System.StageAttempt'], 1))))
        environment: Prometheus-Collector
        variables:
          HELM_SEMVER: $(Build.BuildNumber)
          skipComponentGovernanceDetection: true
        strategy:
          runOnce:
            deploy:
              steps:
              - task: AzureCLI@2
                inputs:
                  azureSubscription: 'prometheus-arc-dev-release-mi'
                  scriptType: 'bash'
                  scriptLocation: 'inlineScript'
                  inlineScript: |
                    # Create JSON request body
                    cat <<EOF > "request.json"
                      {
                        "artifactEndpoints": [
                            {
                                "Regions": [
                                    "westcentralus"
                                ],
                                "Releasetrains": [
                                    "pipeline"
                                ],
                                "FullPathToHelmChart": "https://mcr.microsoft.com/azuremonitor/containerinsights/cidev/ama-metrics-arc",
                                "ExtensionUpdateFrequencyInMinutes": 5,
                                "IsCustomerHidden": true,
                                "ReadyforRollout": true,
                                "RollbackVersion": null,
                                "PackageConfigName": "Microsoft.AzureMonitor.Containers.Metrics-Prom092625"
                            }
                        ]
                      }
                    EOF
                    # Send Request
                    SUBSCRIPTION="b9842c7c-1a38-4385-8f39-a51314758bcf"
                    RESOURCE_AUDIENCE="c699bf69-fb1d-4eaf-999b-99e6b2ae4d85"
                    METHOD="PUT"
                    echo "Request parameter preparation, SUBSCRIPTION is $SUBSCRIPTION, RESOURCE_AUDIENCE is $RESOURCE_AUDIENCE, CHART_VERSION is $HELM_SEMVER"
                    ACCESS_TOKEN=$(az account get-access-token --resource $RESOURCE_AUDIENCE --query accessToken -o json)
                    if [ $? -eq 0 ]; then
                      echo "get access token from resource:$RESOURCE_AUDIENCE successfully."
                    else
                      echo "-e error get access token from resource:$RESOURCE_AUDIENCE failed."
                      exit 1
                    fi
                    ACCESS_TOKEN=$(echo $ACCESS_TOKEN | tr -d '"' | tr -d '"\r\n')
                    ARC_API_URL="https://eastus2euap.dp.kubernetesconfiguration.azure.com"
                    EXTENSION_NAME="microsoft.azuremonitor.containers.metrics"
                    API_VERSION="2021-05-01"
                    echo "start send request"
                    az rest --method $METHOD --headers "{\"Authorization\": \"Bearer $ACCESS_TOKEN\", \"Content-Type\": \"application/json\"}" --body @request.json --uri $ARC_API_URL/subscriptions/$SUBSCRIPTION/extensionTypeRegistrations/$EXTENSION_NAME/versions/$HELM_SEMVER?api-version=$API_VERSION
                    if [ $? -eq 0 ]; then
                      echo "arc extension registered successfully"
                    else
                      echo "-e error failed to register arc extension"
                      exit 1
                    fi
                displayName: "Deploy: Release to dev release train"
              - task: AzureCLI@2
                displayName: "Deploy: wait for ci-dev-arc-wcus cluster to be ready"
                inputs:
                  azureSubscription: 'ContainerInsights_Build_Subscription(9b96ebbd-c57a-42d1-bbe9-b69296e4c7fb)'
                  scriptType: 'bash'
                  scriptLocation: 'inlineScript'
                  inlineScript: |
                    for i in 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20
                      do
                        state=$(az k8s-extension show --name azuremonitor-metrics --cluster-name ci-dev-arc-wcus --resource-group ci-dev-arc-wcus --cluster-type connectedClusters | jq -r '.provisioningState')
                        # We want to wait in case the status is 'Creating' or 'Updating' because of another PR merged shortly before the current one.
                        if [ "$state" = "Succeeded" ] || [ "$state" = "Failed" ]
                        then
                          echo "Cluster is ready to install extension"
                          exit 0
                        fi
                        sleep 30
                      done
                      echo "Cluster is installing a different version of the extension"
                      exit 1
                  retryCountOnTaskFailure: 5
              - task: AzureCLI@2
                displayName: "Deploy: ci-dev-arc-wcus cluster"
                inputs:
                  azureSubscription: 'ContainerInsights_Build_Subscription(9b96ebbd-c57a-42d1-bbe9-b69296e4c7fb)'
                  scriptType: 'bash'
                  scriptLocation: 'inlineScript'
                  inlineScript: |
                    az config set extension.use_dynamic_install=yes_without_prompt
                    az k8s-extension update --name azuremonitor-metrics --resource-group ci-dev-arc-wcus --cluster-name ci-dev-arc-wcus --cluster-type connectedClusters --version $HELM_SEMVER --release-train pipeline
                  retryCountOnTaskFailure: 2

      - deployment: Deploy_AKS_Chart
        displayName: "Deploy/Validate: AKS dev cluster"
        environment: Prometheus-Collector
        condition: or(eq(variables.IS_PR, true), and(eq(variables.IS_MAIN_BRANCH, true), or(not(succeeded('Deploy_AKS_Chart')), eq(variables['System.StageAttempt'], 1))))
        variables:
          HELM_CHART_NAME: $[ stageDependencies.Build.Image_Tags_and_Ev2_Artifacts.outputs['setup.HELM_CHART_NAME'] ]
          HELM_SEMVER: $[ stageDependencies.Build.Image_Tags_and_Ev2_Artifacts.outputs['setup.SEMVER'] ]
          IMAGE_TAG: $[ stageDependencies.Build.Image_Tags_and_Ev2_Artifacts.outputs['setup.SEMVER'] ]
          IMAGE_TAG_WINDOWS: $[ stageDependencies.Build.Image_Tags_and_Ev2_Artifacts.outputs['setup.WINDOWS_IMAGE_TAG'] ]
          HELM_FULL_IMAGE_NAME: $[ stageDependencies.Build.Image_Tags_and_Ev2_Artifacts.outputs['setup.HELM_FULL_IMAGE_NAME'] ]
          IMAGE_TAG_TARGET_ALLOCATOR: $[ stageDependencies.Build.Image_Tags_and_Ev2_Artifacts.outputs['setup.TARGET_ALLOCATOR_IMAGE_TAG'] ]
          IMAGE_TAG_CONFIG_READER: $[ stageDependencies.Build.Image_Tags_and_Ev2_Artifacts.outputs['setup.LINUX_CONFIG_READER_IMAGE_TAG'] ]
          RETINA_VERSION: $[ stageDependencies.Build.DevClusterHelmChartFiles.outputs['setup.RETINA_VERSION'] ]
          skipComponentGovernanceDetection: true
        templateContext:
            type: releaseJob
            isProduction: false
            inputs:
            - input: pipelineArtifact
              artifactName: dev-cluster-helm-chart
              targetPath: $(Pipeline.Workspace)
        strategy:
          runOnce:
            deploy:
              steps:
              - task: HelmInstaller@1
                displayName: Install Helm version
                inputs:
                  helmVersionToInstall: $(HELM_VERSION)
              - bash: |
                  for i in 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20
                      do
                        sleep 30
                        echo $(IMAGE_TAG)
                        echo $(IMAGE_TAG_WINDOWS)
                        echo $(IMAGE_TAG_TARGET_ALLOCATOR)
                        echo $(IMAGE_TAG_CONFIG_READER)
                        output=$(curl -s https://$(MCR_REGISTRY)/v2$(MCR_REPOSITORY)/tags/list)
                        if (echo $output | grep $(IMAGE_TAG_WINDOWS)) && (echo $output | grep $(IMAGE_TAG)) && (echo $output | grep $(IMAGE_TAG_TARGET_ALLOCATOR)) && (echo $output | grep $(IMAGE_TAG_CONFIG_READER))
                        then
                          echo "Images are published to mcr"
                          exit 0
                        fi
                      done
                      echo "Images are not published to mcr within the timeout"
                      exit 1
                displayName: "Check images are pushed to dev MCR"
                condition: eq(variables.IS_PR, false)
                retryCountOnTaskFailure: 2
              - bash: |
                  export AKS_REGION="eastus"
                  export AKS_RESOURCE_ID="/subscriptions/9b96ebbd-c57a-42d1-bbe9-b69296e4c7fb/resourceGroups/ci-dev-aks-mac-eus-rg/providers/Microsoft.ContainerService/managedClusters/ci-dev-aks-mac-eus"
                  export ARC_EXTENSION="false"
                  envsubst < $(Pipeline.Workspace)/azure-monitor-metrics-addon/Chart-template.yaml > $(Pipeline.Workspace)/azure-monitor-metrics-addon/Chart.yaml && envsubst < $(Pipeline.Workspace)/azure-monitor-metrics-addon/values-template.yaml > $(Pipeline.Workspace)/azure-monitor-metrics-addon/values.yaml
                  ls $(Pipeline.Workspace)/azure-monitor-metrics-addon
                  cd $(Pipeline.Workspace)/azure-monitor-metrics-addon
                  helm dependency update
                displayName: "Deploy: substitute chart version for 3p in Chart.yaml and values.yaml"
              - bash: |
                  if [ "$(IS_PR)" = "True" ]; then
                    echo "##vso[task.setvariable variable=HELM_DRY_RUN_FLAG]--dry-run"
                    echo "PR mode: Will validate charts with --dry-run (no actual deployment)"
                  else
                    echo "##vso[task.setvariable variable=HELM_DRY_RUN_FLAG]"
                    echo "Main branch: Will perform actual deployment"
                  fi
                displayName: "Set dry-run flag based on PR status"
              - task: HelmDeploy@0
                displayName: "Deploy/Validate: ci-dev-aks-mac-eus cluster"
                inputs:
                  connectionType: 'Azure Resource Manager'
                  azureSubscription: 'ContainerInsights_Build_Subscription(9b96ebbd-c57a-42d1-bbe9-b69296e4c7fb)'
                  azureResourceGroup: 'ci-dev-aks-mac-eus-rg'
                  kubernetesCluster: 'ci-dev-aks-mac-eus'
                  namespace: 'default'
                  command: 'upgrade'
                  chartType: 'FilePath'
                  chartPath: '$(Pipeline.Workspace)/azure-monitor-metrics-addon/'
                  releaseName: 'ama-metrics'
                  waitForExecution: false
                  arguments: --dependency-update --values $(Pipeline.Workspace)/azure-monitor-metrics-addon/values.yaml $(HELM_DRY_RUN_FLAG)
              - task: HelmDeploy@1
                displayName: "Deploy/Validate: retina onto ci-dev-aks-mac-eus cluster"
                inputs:
                  connectionType: 'Azure Resource Manager'
                  azureSubscription: 'ContainerInsights_Build_Subscription(9b96ebbd-c57a-42d1-bbe9-b69296e4c7fb)'
                  azureResourceGroup: 'ci-dev-aks-mac-eus-rg'
                  kubernetesCluster: 'ci-dev-aks-mac-eus'
                  namespace: 'kube-system'
                  command: 'upgrade'
                  chartType: 'FilePath'
                  chartPath: '$(Pipeline.Workspace)/retina'
                  releaseName: 'retina'
                  waitForExecution: false
                  arguments: --install --values $(Pipeline.Workspace)/retina/values.yaml --skip-crds --version $(RETINA_VERSION) --set operator.enabled=true --set enabledPlugin_linux="\[dropreason\,packetforward\,linuxutil\,dns\,packetparser\]" --set logLevel=info --set operator.enableRetinaEndpoint=true --set image.tag=$(RETINA_VERSION) --set operator.tag=$(RETINA_VERSION) --set tolerations[0].key=CriticalAddonsOnly --set tolerations[0].operator=Exists --set tolerations[1].operator=Exists --set tolerations[1].effect=NoExecute --set tolerations[2].operator=Exists --set tolerations[2].effect=NoSchedule $(HELM_DRY_RUN_FLAG)

      - deployment: Deploy_AKS_Chart_Test_Cluster
        displayName: "Deploy/Validate: AKS tests cluster"
        environment: Prometheus-Collector
        condition: or(eq(variables.IS_PR, true), and(eq(variables.IS_MAIN_BRANCH, true), or(not(succeeded('Deploy_AKS_Chart_Test_Cluster')), eq(variables['System.StageAttempt'], 1))))
        variables:
          HELM_CHART_NAME: $[ stageDependencies.Build.Image_Tags_and_Ev2_Artifacts.outputs['setup.HELM_CHART_NAME'] ]
          HELM_SEMVER: $[ stageDependencies.Build.Image_Tags_and_Ev2_Artifacts.outputs['setup.SEMVER'] ]
          IMAGE_TAG: $[ stageDependencies.Build.Image_Tags_and_Ev2_Artifacts.outputs['setup.SEMVER'] ]
          IMAGE_TAG_WINDOWS: $[ stageDependencies.Build.Image_Tags_and_Ev2_Artifacts.outputs['setup.WINDOWS_IMAGE_TAG'] ]
          HELM_FULL_IMAGE_NAME: $[ stageDependencies.Build.Image_Tags_and_Ev2_Artifacts.outputs['setup.HELM_FULL_IMAGE_NAME'] ]
          IMAGE_TAG_TARGET_ALLOCATOR: $[ stageDependencies.Build.Image_Tags_and_Ev2_Artifacts.outputs['setup.TARGET_ALLOCATOR_IMAGE_TAG'] ]
          IMAGE_TAG_CONFIG_READER: $[ stageDependencies.Build.Image_Tags_and_Ev2_Artifacts.outputs['setup.LINUX_CONFIG_READER_IMAGE_TAG'] ]
          RETINA_VERSION: $[ stageDependencies.Build.DevClusterHelmChartFiles.outputs['setup.RETINA_VERSION'] ]
          skipComponentGovernanceDetection: true
        templateContext:
            type: releaseJob
            isProduction: false
            inputs:
            - input: pipelineArtifact
              artifactName: dev-cluster-helm-chart
              targetPath: $(Pipeline.Workspace)
        strategy:
          runOnce:
            deploy:
              steps:
              - task: HelmInstaller@1
                displayName: Install Helm version
                inputs:
                  helmVersionToInstall: $(HELM_VERSION)
              - bash: |
                  for i in 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20
                      do
                        sleep 30
                        echo $(IMAGE_TAG)
                        echo $(IMAGE_TAG_WINDOWS)
                        echo $(IMAGE_TAG_TARGET_ALLOCATOR)
                        echo $(IMAGE_TAG_CONFIG_READER)
                        output=$(curl -s https://$(MCR_REGISTRY)/v2$(MCR_REPOSITORY)/tags/list)
                        if (echo $output | grep $(IMAGE_TAG_WINDOWS)) && (echo $output | grep $(IMAGE_TAG)) && (echo $output | grep $(IMAGE_TAG_TARGET_ALLOCATOR)) && (echo $output | grep $(IMAGE_TAG_CONFIG_READER))
                        then
                          echo "Images are published to mcr"
                          exit 0
                        fi
                      done
                      echo "Images are not published to mcr within the timeout"
                      exit 1
                displayName: "Check images are pushed to dev MCR"
                condition: eq(variables.IS_PR, false)
                retryCountOnTaskFailure: 2
              - bash: |
                  export AKS_REGION="centralus"
                  export AKS_RESOURCE_ID="/subscriptions/9b96ebbd-c57a-42d1-bbe9-b69296e4c7fb/resourcegroups/ci-dev-aks-tests/providers/Microsoft.ContainerService/managedClusters/ci-dev-aks-tests"
                  export ARC_EXTENSION="false"
                  envsubst < $(Pipeline.Workspace)/azure-monitor-metrics-addon/Chart-template.yaml > $(Pipeline.Workspace)/azure-monitor-metrics-addon/Chart.yaml && envsubst < $(Pipeline.Workspace)/azure-monitor-metrics-addon/values-template.yaml > $(Pipeline.Workspace)/azure-monitor-metrics-addon/values.yaml
                  ls $(Pipeline.Workspace)/azure-monitor-metrics-addon
                  cd $(Pipeline.Workspace)/azure-monitor-metrics-addon
                  helm dependency update
                displayName: "Build: substitute chart version for 3p in Chart.yaml and values.yaml"
              - bash: |
                  if [ "$(IS_PR)" = "True" ]; then
                    echo "##vso[task.setvariable variable=HELM_DRY_RUN_FLAG]--dry-run"
                    echo "PR mode: Will validate charts with --dry-run (no actual deployment)"
                  else
                    echo "##vso[task.setvariable variable=HELM_DRY_RUN_FLAG]"
                    echo "Main branch: Will perform actual deployment"
                  fi
                displayName: "Set dry-run flag based on PR status"
              - task: HelmDeploy@0
                displayName: "Deploy/Validate: ci-dev-aks-tests cluster"
                inputs:
                  connectionType: 'Azure Resource Manager'
                  azureSubscription: 'ContainerInsights_Build_Subscription(9b96ebbd-c57a-42d1-bbe9-b69296e4c7fb)'
                  azureResourceGroup: 'ci-dev-aks-tests'
                  kubernetesCluster: 'ci-dev-aks-tests'
                  namespace: 'default'
                  command: 'upgrade'
                  chartType: 'FilePath'
                  chartPath: '$(Pipeline.Workspace)/azure-monitor-metrics-addon/'
                  releaseName: 'ama-metrics'
                  waitForExecution: false
                  arguments: --dependency-update --values $(Pipeline.Workspace)/azure-monitor-metrics-addon/values.yaml $(HELM_DRY_RUN_FLAG)


      - deployment: Deploy_AKS_Chart_OTel_Cluster
        displayName: "Deploy/Validate: AKS OTEL cluster"
        environment: Prometheus-Collector
        condition: or(eq(variables.IS_PR, true), and(eq(variables.IS_MAIN_BRANCH, true), or(not(succeeded('Deploy_AKS_Chart_OTel_Cluster')), eq(variables['System.StageAttempt'], 1))))
        variables:
          HELM_CHART_NAME: $[ stageDependencies.Build.Image_Tags_and_Ev2_Artifacts.outputs['setup.HELM_CHART_NAME'] ]
          HELM_SEMVER: $[ stageDependencies.Build.Image_Tags_and_Ev2_Artifacts.outputs['setup.SEMVER'] ]
          IMAGE_TAG: $[ stageDependencies.Build.Image_Tags_and_Ev2_Artifacts.outputs['setup.SEMVER'] ]
          IMAGE_TAG_WINDOWS: $[ stageDependencies.Build.Image_Tags_and_Ev2_Artifacts.outputs['setup.WINDOWS_IMAGE_TAG'] ]
          HELM_FULL_IMAGE_NAME: $[ stageDependencies.Build.Image_Tags_and_Ev2_Artifacts.outputs['setup.HELM_FULL_IMAGE_NAME'] ]
          IMAGE_TAG_TARGET_ALLOCATOR: $[ stageDependencies.Build.Image_Tags_and_Ev2_Artifacts.outputs['setup.TARGET_ALLOCATOR_IMAGE_TAG'] ]
          IMAGE_TAG_CONFIG_READER: $[ stageDependencies.Build.Image_Tags_and_Ev2_Artifacts.outputs['setup.LINUX_CONFIG_READER_IMAGE_TAG'] ]
          RETINA_VERSION: $[ stageDependencies.Build.DevClusterHelmChartFiles.outputs['setup.RETINA_VERSION'] ]
          skipComponentGovernanceDetection: true
        templateContext:
            type: releaseJob
            isProduction: false
            inputs:
            - input: pipelineArtifact
              artifactName: dev-cluster-helm-chart
              targetPath: $(Pipeline.Workspace)
        strategy:
          runOnce:
            deploy:
              steps:
              - task: HelmInstaller@1
                displayName: Install Helm version
                inputs:
                  helmVersionToInstall: $(HELM_VERSION)
              - bash: |
                  for i in 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20
                      do
                        sleep 30
                        echo $(IMAGE_TAG)
                        echo $(IMAGE_TAG_WINDOWS)
                        echo $(IMAGE_TAG_TARGET_ALLOCATOR)
                        echo $(IMAGE_TAG_CONFIG_READER)
                        output=$(curl -s https://$(MCR_REGISTRY)/v2$(MCR_REPOSITORY)/tags/list)
                        if (echo $output | grep $(IMAGE_TAG_WINDOWS)) && (echo $output | grep $(IMAGE_TAG)) && (echo $output | grep $(IMAGE_TAG_TARGET_ALLOCATOR)) && (echo $output | grep $(IMAGE_TAG_CONFIG_READER))
                        then
                          echo "Images are published to mcr"
                          exit 0
                        fi
                      done
                      echo "Images are not published to mcr within the timeout"
                      exit 1
                displayName: "Check images are pushed to dev MCR"
                condition: eq(variables.IS_PR, false)
                retryCountOnTaskFailure: 2
              - bash: |
                  export AKS_REGION="westus3"
                  export AKS_RESOURCE_ID="/subscriptions/9b96ebbd-c57a-42d1-bbe9-b69296e4c7fb/resourceGroups/ciprom-dev-aks-otlp/providers/Microsoft.ContainerService/managedClusters/ciprom-dev-aks-otlp"
                  export ARC_EXTENSION="false"
                  envsubst < $(Pipeline.Workspace)/azure-monitor-metrics-addon/Chart-template.yaml > $(Pipeline.Workspace)/azure-monitor-metrics-addon/Chart.yaml && envsubst < $(Pipeline.Workspace)/azure-monitor-metrics-addon/values-template.yaml > $(Pipeline.Workspace)/azure-monitor-metrics-addon/values.yaml
                  ls $(Pipeline.Workspace)/azure-monitor-metrics-addon
                  cd $(Pipeline.Workspace)/azure-monitor-metrics-addon
                  helm dependency update
                displayName: "Build: substitute chart version for 3p in Chart.yaml and values.yaml"
              - bash: |
                  if [ "$(IS_PR)" = "True" ]; then
                    echo "##vso[task.setvariable variable=HELM_DRY_RUN_FLAG]--dry-run"
                    echo "PR mode: Will validate charts with --dry-run (no actual deployment)"
                  else
                    echo "##vso[task.setvariable variable=HELM_DRY_RUN_FLAG]"
                    echo "Main branch: Will perform actual deployment"
                  fi
                displayName: "Set dry-run flag based on PR status"
              - task: HelmDeploy@0
                displayName: "Deploy/Validate: ciprom-dev-aks-otlp cluster"
                inputs:
                  connectionType: 'Azure Resource Manager'
                  azureSubscription: 'ContainerInsights_Build_Subscription(9b96ebbd-c57a-42d1-bbe9-b69296e4c7fb)'
                  azureResourceGroup: 'ciprom-dev-aks-otlp'
                  kubernetesCluster: 'ciprom-dev-aks-otlp'
                  namespace: 'default'
                  command: 'upgrade'
                  chartType: 'FilePath'
                  chartPath: '$(Pipeline.Workspace)/azure-monitor-metrics-addon/'
                  releaseName: 'ama-metrics'
                  waitForExecution: false
                  arguments: --dependency-update --values $(Pipeline.Workspace)/azure-monitor-metrics-addon/values.yaml $(HELM_DRY_RUN_FLAG)
              - task: HelmDeploy@1
                displayName: "Deploy/Validate: retina onto ciprom-dev-aks-otlp cluster"
                inputs:
                  connectionType: 'Azure Resource Manager'
                  azureSubscription: 'ContainerInsights_Build_Subscription(9b96ebbd-c57a-42d1-bbe9-b69296e4c7fb)'
                  azureResourceGroup: 'ciprom-dev-aks-otlp'
                  kubernetesCluster: 'ciprom-dev-aks-otlp'
                  namespace: 'kube-system'
                  command: 'upgrade'
                  chartType: 'FilePath'
                  chartPath: '$(Pipeline.Workspace)/retina'
                  releaseName: 'retina'
                  waitForExecution: false
                  arguments: --install --values $(Pipeline.Workspace)/retina/values.yaml --skip-crds --version $(RETINA_VERSION) --set operator.enabled=true --set enabledPlugin_linux="\[dropreason\,packetforward\,linuxutil\,dns\,packetparser\]" --set logLevel=info --set operator.enableRetinaEndpoint=true --set image.tag=$(RETINA_VERSION) --set operator.tag=$(RETINA_VERSION) --set tolerations[0].key=CriticalAddonsOnly --set tolerations[0].operator=Exists --set tolerations[1].operator=Exists --set tolerations[1].effect=NoExecute --set tolerations[2].operator=Exists --set tolerations[2].effect=NoSchedule $(HELM_DRY_RUN_FLAG)

      - deployment: Deploy_AKS_Chart_OTel_Upgrade_Cluster
        displayName: "Deploy: AKS OTel Upgrade cluster"
        environment: Prometheus-Collector
        condition: and(succeeded(), eq(variables.IS_OTEL_UPGRADE_BRANCH, true))
        variables:
          HELM_CHART_NAME: $[ stageDependencies.Build.Image_Tags_and_Ev2_Artifacts.outputs['setup.HELM_CHART_NAME'] ]
          HELM_SEMVER: $[ stageDependencies.Build.Image_Tags_and_Ev2_Artifacts.outputs['setup.SEMVER'] ]
          IMAGE_TAG: $[ stageDependencies.Build.Image_Tags_and_Ev2_Artifacts.outputs['setup.SEMVER'] ]
          IMAGE_TAG_WINDOWS: $[ stageDependencies.Build.Image_Tags_and_Ev2_Artifacts.outputs['setup.WINDOWS_IMAGE_TAG'] ]
          HELM_FULL_IMAGE_NAME: $[ stageDependencies.Build.Image_Tags_and_Ev2_Artifacts.outputs['setup.HELM_FULL_IMAGE_NAME'] ]
          IMAGE_TAG_TARGET_ALLOCATOR: $[ stageDependencies.Build.Image_Tags_and_Ev2_Artifacts.outputs['setup.TARGET_ALLOCATOR_IMAGE_TAG'] ]
          IMAGE_TAG_CONFIG_READER: $[ stageDependencies.Build.Image_Tags_and_Ev2_Artifacts.outputs['setup.LINUX_CONFIG_READER_IMAGE_TAG'] ]
          RETINA_VERSION: $[ stageDependencies.Build.DevClusterHelmChartFiles.outputs['setup.RETINA_VERSION'] ]
          skipComponentGovernanceDetection: true
        templateContext:
            type: releaseJob
            isProduction: false
            inputs:
            - input: pipelineArtifact
              artifactName: dev-cluster-helm-chart
              targetPath: $(Pipeline.Workspace)
        strategy:
          runOnce:
            deploy:
              steps:
              - task: HelmInstaller@1
                displayName: Install Helm version
                inputs:
                  helmVersionToInstall: $(HELM_VERSION)
              - bash: |
                  for i in 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20
                      do
                        sleep 30
                        echo $(IMAGE_TAG)
                        echo $(IMAGE_TAG_WINDOWS)
                        echo $(IMAGE_TAG_TARGET_ALLOCATOR)
                        echo $(IMAGE_TAG_CONFIG_READER)
                        output=$(curl -s https://$(MCR_REGISTRY)/v2$(MCR_REPOSITORY)/tags/list)
                        if (echo $output | grep $(IMAGE_TAG_WINDOWS)) && (echo $output | grep $(IMAGE_TAG)) && (echo $output | grep $(IMAGE_TAG_TARGET_ALLOCATOR)) && (echo $output | grep $(IMAGE_TAG_CONFIG_READER))
                        then
                          echo "Images are published to mcr"
                          exit 0
                        fi
                      done
                      echo "Images are not published to mcr within the timeout"
                      exit 1
                displayName: "Check images are pushed to dev MCR"
                retryCountOnTaskFailure: 2
              - bash: |
                  export AKS_REGION="westus3"
                  export AKS_RESOURCE_ID="/subscriptions/9b96ebbd-c57a-42d1-bbe9-b69296e4c7fb/resourceGroups/ciprom-upgrade-bot/providers/Microsoft.ContainerService/managedClusters/ciprom-upgrade-bot"
                  export ARC_EXTENSION="false"
                  envsubst < $(Pipeline.Workspace)/azure-monitor-metrics-addon/Chart-template.yaml > $(Pipeline.Workspace)/azure-monitor-metrics-addon/Chart.yaml && envsubst < $(Pipeline.Workspace)/azure-monitor-metrics-addon/values-template.yaml > $(Pipeline.Workspace)/azure-monitor-metrics-addon/values.yaml
                  ls $(Pipeline.Workspace)/azure-monitor-metrics-addon
                  cd $(Pipeline.Workspace)/azure-monitor-metrics-addon
                  helm dependency update
                displayName: "Build: substitute chart version for 3p in Chart.yaml and values.yaml"
              - task: HelmDeploy@0
                displayName: "Deploy: ciprom-upgrade-bot cluster"
                inputs:
                  connectionType: 'Azure Resource Manager'
                  azureSubscription: 'ContainerInsights_Build_Subscription(9b96ebbd-c57a-42d1-bbe9-b69296e4c7fb)'
                  azureResourceGroup: 'ciprom-upgrade-bot'
                  kubernetesCluster: 'ciprom-upgrade-bot'
                  namespace: 'default'
                  command: 'upgrade'
                  chartType: 'FilePath'
                  chartPath: '$(Pipeline.Workspace)/azure-monitor-metrics-addon/'
                  releaseName: 'ama-metrics'
                  waitForExecution: false
                  arguments: --dependency-update --values $(Pipeline.Workspace)/azure-monitor-metrics-addon/values.yaml
              - task: HelmDeploy@1
                displayName: "Deploy: retina onto ciprom-upgrade-bot cluster"
                inputs:
                  connectionType: 'Azure Resource Manager'
                  azureSubscription: 'ContainerInsights_Build_Subscription(9b96ebbd-c57a-42d1-bbe9-b69296e4c7fb)'
                  azureResourceGroup: 'ciprom-upgrade-bot'
                  kubernetesCluster: 'ciprom-upgrade-bot'
                  namespace: 'kube-system'
                  command: 'upgrade'
                  chartType: 'FilePath'
                  chartPath: '$(Pipeline.Workspace)/retina'
                  releaseName: 'retina'
                  waitForExecution: false
                  arguments: --install --values $(Pipeline.Workspace)/retina/values.yaml --skip-crds --version $(RETINA_VERSION) --set operator.enabled=true --set enabledPlugin_linux="\[dropreason\,packetforward\,linuxutil\,dns\,packetparser\]" --set logLevel=info --set operator.enableRetinaEndpoint=true --set image.tag=$(RETINA_VERSION) --set operator.tag=$(RETINA_VERSION) --set tolerations[0].key=CriticalAddonsOnly --set tolerations[0].operator=Exists --set tolerations[1].operator=Exists --set tolerations[1].effect=NoExecute --set tolerations[2].operator=Exists --set tolerations[2].effect=NoSchedule

      - deployment: Testkube
        displayName: "Test: AKS testkube tests"
        environment: Prometheus-Collector
        dependsOn: Deploy_AKS_Chart
        condition: and(succeeded(), and(eq(variables.IS_PR, false), eq(variables.IS_MAIN_BRANCH, true)))
        variables:
          HELM_CHART_NAME: $[ stageDependencies.Build.Image_Tags_and_Ev2_Artifacts.outputs['setup.HELM_CHART_NAME'] ]
          HELM_SEMVER: $[ stageDependencies.Build.Image_Tags_and_Ev2_Artifacts.outputs['setup.SEMVER'] ]
          IMAGE_TAG: $[ stageDependencies.Build.Image_Tags_and_Ev2_Artifacts.outputs['setup.SEMVER'] ]
          IMAGE_TAG_WINDOWS: $[ stageDependencies.Build.Image_Tags_and_Ev2_Artifacts.outputs['setup.WINDOWS_IMAGE_TAG'] ]
          HELM_FULL_IMAGE_NAME: $[ stageDependencies.Build.Image_Tags_and_Ev2_Artifacts.outputs['setup.HELM_FULL_IMAGE_NAME'] ]
          skipComponentGovernanceDetection: true
        templateContext:
          type: releaseJob
          isProduction: false
          inputs:
          - input: pipelineArtifact
            artifactName: testkube-test-files
            targetPath: $(Pipeline.Workspace)
        strategy:
          runOnce:
            deploy:
              steps:
              - task: AzureCLI@1
                displayName: Get kubeconfig
                inputs:
                  azureSubscription: 'ContainerInsights_Build_Subscription(9b96ebbd-c57a-42d1-bbe9-b69296e4c7fb)'
                  scriptLocation: 'inlineScript'
                  inlineScript: 'az aks get-credentials -g ci-dev-aks-mac-eus-rg -n ci-dev-aks-mac-eus'
              - bash: |
                  export BUILD_ARTIFACTSTAGINGDIRECTORY="$(Build.ArtifactStagingDirectory)"
                  export BUILD_BUILDID="$(Build.BuildId)"
                  export SYSTEM_JOBID="$(System.JobId)"
                  export SYSTEM_TASKINSTANCEID="$(System.TaskInstanceId)"
                  chmod +x ./testkube/run-testkube-workflow.sh
                  ./testkube/run-testkube-workflow.sh \
                    "https://ci-dev-aks-eus-mac-mih6.eastus.prometheus.monitor.azure.com" \
                    "c7f895bb-c4f6-45af-be82-2273a424e237" \
                    "testkube-test-crs.yaml" \
                    "testkube-test-crs-ci-dev-aks-mac-eus.yaml" \
                    "" \
                    "" \
                    "AKS"
                workingDirectory: $(Pipeline.Workspace)
                displayName: "Run TestKube workflow"
                continueOnError: true
              - bash: |
                  if [ -f "$(Build.ArtifactStagingDirectory)/testkube-results-AKS.json" ]; then
                    # Read the JSON content and set it as a pipeline variable
                    TESTKUBE_RESULTS_AKS=$(cat "$(Build.ArtifactStagingDirectory)/testkube-results-AKS.json" | jq -c . | tr -d '\n\r')
                    echo "##vso[task.setvariable variable=TESTKUBE_RESULTS_AKS;isOutput=true]$TESTKUBE_RESULTS_AKS"
                    echo "TestKube AKS results set as pipeline variable"
                    echo $TESTKUBE_RESULTS_AKS
                  else
                    echo "##vso[task.setvariable variable=TESTKUBE_RESULTS_AKS;isOutput=true]{\"environment\":\"AKS\",\"status\":\"failed\",\"message\":\"Results file not found\"}"
                    echo "TestKube AKS results file not found, setting default failure result"
                  fi
                displayName: "Set TestKube AKS Results as Pipeline Variable"
                continueOnError: true
                name: testkube_results
              - bash: |
                  if [ -f "$(Build.ArtifactStagingDirectory)/testkube-results-AKS.json" ]; then
                    TEST_STATUS=$(cat "$(Build.ArtifactStagingDirectory)/testkube-results-AKS.json" | jq -r '.status')
                    if [ "$TEST_STATUS" = "failed" ]; then
                      echo "##vso[task.logissue type=error]TestKube tests failed"
                      echo "##vso[task.complete result=Failed;]TestKube tests failed"
                      exit 1
                    fi
                  else
                    echo "##vso[task.logissue type=error]TestKube results file not found"
                    echo "##vso[task.complete result=Failed;]TestKube results file not found"
                    exit 1
                  fi
                displayName: "Fail job if TestKube tests failed"

      - deployment: Testkube_OTel
        displayName: "Test: OTel AKS testkube tests"
        environment: Prometheus-Collector
        dependsOn: Deploy_AKS_Chart_OTel_Cluster
        condition: and(succeeded(), and(eq(variables.IS_PR, false), eq(variables.IS_MAIN_BRANCH, true)))
        variables:
          HELM_CHART_NAME: $[ stageDependencies.Build.Image_Tags_and_Ev2_Artifacts.outputs['setup.HELM_CHART_NAME'] ]
          HELM_SEMVER: $[ stageDependencies.Build.Image_Tags_and_Ev2_Artifacts.outputs['setup.SEMVER'] ]
          IMAGE_TAG: $[ stageDependencies.Build.Image_Tags_and_Ev2_Artifacts.outputs['setup.SEMVER'] ]
          IMAGE_TAG_WINDOWS: $[ stageDependencies.Build.Image_Tags_and_Ev2_Artifacts.outputs['setup.WINDOWS_IMAGE_TAG'] ]
          HELM_FULL_IMAGE_NAME: $[ stageDependencies.Build.Image_Tags_and_Ev2_Artifacts.outputs['setup.HELM_FULL_IMAGE_NAME'] ]
          skipComponentGovernanceDetection: true
        templateContext:
          type: releaseJob
          isProduction: false
          inputs:
          - input: pipelineArtifact
            artifactName: testkube-test-files
            targetPath: $(Pipeline.Workspace)
        strategy:
          runOnce:
            deploy:
              steps:
              - task: AzureCLI@1
                displayName: Get kubeconfig
                inputs:
                  azureSubscription: 'ContainerInsights_Build_Subscription(9b96ebbd-c57a-42d1-bbe9-b69296e4c7fb)'
                  scriptLocation: 'inlineScript'
                  inlineScript: 'az aks get-credentials --resource-group ciprom-dev-aks-otlp --name ciprom-dev-aks-otlp'
              - bash: |
                  export BUILD_ARTIFACTSTAGINGDIRECTORY="$(Build.ArtifactStagingDirectory)"
                  export BUILD_BUILDID="$(Build.BuildId)"
                  export SYSTEM_JOBID="$(System.JobId)"
                  export SYSTEM_TASKINSTANCEID="$(System.TaskInstanceId)"
                  chmod +x ./testkube/run-testkube-workflow.sh
                  ./testkube/run-testkube-workflow.sh \
                    "https://ci-prom-dev-aks-otlp-geaqdgeuapfeh8b2.westus3.prometheus.monitor.azure.com" \
                    "6b8f6333-ecd0-4579-b05d-afc98a103a59" \
                    "testkube-test-crs-otel.yaml" \
                    "testkube-test-crs-ciprom-dev-aks-otlp.yaml" \
                    "false" \
                    "" \
                    "OTel"
                workingDirectory: $(Pipeline.Workspace)
                displayName: "Run TestKube workflow"
                continueOnError: true
              - bash: |
                  if [ -f "$(Build.ArtifactStagingDirectory)/testkube-results-OTel.json" ]; then
                    # Read the JSON content and set it as a pipeline variable
                    TESTKUBE_RESULTS_OTEL=$(cat "$(Build.ArtifactStagingDirectory)/testkube-results-OTel.json" | jq -c . | tr -d '\n\r')
                    echo "##vso[task.setvariable variable=TESTKUBE_RESULTS_OTEL;isOutput=true]$TESTKUBE_RESULTS_OTEL"
                    echo "TestKube OTel results set as pipeline variable"
                    echo $TESTKUBE_RESULTS_OTEL
                  else
                    echo "##vso[task.setvariable variable=TESTKUBE_RESULTS_OTEL;isOutput=true]{\"environment\":\"OTel\",\"status\":\"failed\",\"message\":\"Results file not found\"}"
                    echo "TestKube OTel results file not found, setting default failure result"
                  fi
                displayName: "Set TestKube OTel Results as Pipeline Variable"
                continueOnError: true
                name: testkube_results
              - bash: |
                  if [ -f "$(Build.ArtifactStagingDirectory)/testkube-results-OTel.json" ]; then
                    TEST_STATUS=$(cat "$(Build.ArtifactStagingDirectory)/testkube-results-OTel.json" | jq -r '.status')
                    if [ "$TEST_STATUS" = "failed" ]; then
                      echo "##vso[task.logissue type=error]TestKube tests failed"
                      echo "##vso[task.complete result=Failed;]TestKube tests failed"
                      exit 1
                    fi
                  else
                    echo "##vso[task.logissue type=error]TestKube results file not found"
                    echo "##vso[task.complete result=Failed;]TestKube results file not found"
                    exit 1
                  fi
                displayName: "Fail job if TestKube tests failed"
    
      - deployment: Testkube_ARC
        displayName: "Test: Arc testkube tests"
        environment: Prometheus-Collector
        dependsOn: Deploy_Chart_ARC
        condition: and(succeeded(), and(eq(variables.IS_PR, false), eq(variables.IS_MAIN_BRANCH, true)))
        variables:
          HELM_CHART_NAME: $[ stageDependencies.Build.Image_Tags_and_Ev2_Artifacts.outputs['setup.HELM_CHART_NAME'] ]
          HELM_SEMVER: $[ stageDependencies.Build.Image_Tags_and_Ev2_Artifacts.outputs['setup.SEMVER'] ]
          IMAGE_TAG: $[ stageDependencies.Build.Image_Tags_and_Ev2_Artifacts.outputs['setup.SEMVER'] ]
          IMAGE_TAG_WINDOWS: $[ stageDependencies.Build.Image_Tags_and_Ev2_Artifacts.outputs['setup.WINDOWS_IMAGE_TAG'] ]
          HELM_FULL_IMAGE_NAME: $[ stageDependencies.Build.Image_Tags_and_Ev2_Artifacts.outputs['setup.HELM_FULL_IMAGE_NAME'] ]
          skipComponentGovernanceDetection: true
        templateContext:
          type: releaseJob
          isProduction: false
          inputs:
          - input: pipelineArtifact
            artifactName: testkube-test-files
            targetPath: $(Pipeline.Workspace)
        strategy:
          runOnce:
            deploy:
              steps:
              - task: AzureCLI@1
                displayName: Get kubeconfig
                inputs:
                  azureSubscription: 'ContainerInsights_Build_Subscription(9b96ebbd-c57a-42d1-bbe9-b69296e4c7fb)'
                  scriptLocation: 'inlineScript'
                  inlineScript: 'az aks get-credentials -g ci-dev-arc-wcus -n ci-dev-arc-wcus'
              - bash: |
                  export BUILD_ARTIFACTSTAGINGDIRECTORY="$(Build.ArtifactStagingDirectory)"
                  export BUILD_BUILDID="$(Build.BuildId)"
                  export SYSTEM_JOBID="$(System.JobId)"
                  export SYSTEM_TASKINSTANCEID="$(System.TaskInstanceId)"
                  chmod +x ./testkube/run-testkube-workflow.sh
                  ./testkube/run-testkube-workflow.sh \
                  "https://ci-dev-arc-amw-p3eu.eastus.prometheus.monitor.azure.com" \
                  "5f13547e-a4e2-4efd-85fe-a2b03d5b8661" \
                  "testkube-test-crs-arc.yaml" \
                  "testkube-test-crs-ci-dev-arc-wcus.yaml" \
                  "" \
                  "" \
                  "ARC"
                workingDirectory: $(Pipeline.Workspace)
                displayName: "Run TestKube workflow"
                continueOnError: true
              - bash: |
                  if [ -f "$(Build.ArtifactStagingDirectory)/testkube-results-ARC.json" ]; then
                    # Read the JSON content and set it as a pipeline variable
                    TESTKUBE_RESULTS_ARC=$(cat "$(Build.ArtifactStagingDirectory)/testkube-results-ARC.json" | jq -c . | tr -d '\n\r')
                    echo "##vso[task.setvariable variable=TESTKUBE_RESULTS_ARC;isOutput=true]$TESTKUBE_RESULTS_ARC"
                    echo "TestKube ARC results set as pipeline variable"
                    echo $TESTKUBE_RESULTS_ARC
                  else
                    echo "##vso[task.setvariable variable=TESTKUBE_RESULTS_ARC;isOutput=true]{\"environment\":\"ARC\",\"status\":\"failed\",\"message\":\"Results file not found\"}"
                    echo "TestKube ARC results file not found, setting default failure result"
                  fi
                displayName: "Set TestKube ARC Results as Pipeline Variable"
                continueOnError: true
                name: testkube_results
              - bash: |
                  if [ -f "$(Build.ArtifactStagingDirectory)/testkube-results-ARC.json" ]; then
                    TEST_STATUS=$(cat "$(Build.ArtifactStagingDirectory)/testkube-results-ARC.json" | jq -r '.status')
                    if [ "$TEST_STATUS" = "failed" ]; then
                      echo "##vso[task.logissue type=error]TestKube tests failed"
                      echo "##vso[task.complete result=Failed;]TestKube tests failed"
                      exit 1
                    fi
                  else
                    echo "##vso[task.logissue type=error]TestKube results file not found"
                    echo "##vso[task.complete result=Failed;]TestKube results file not found"
                    exit 1
                  fi
                displayName: "Fail job if TestKube tests failed"

      - deployment: Testkube_OTel_Upgrade
        displayName: "Test: OTel Collector Upgrade testkube tests"
        environment: Prometheus-Collector
        dependsOn:  Deploy_AKS_Chart_OTel_Upgrade_Cluster
        condition: eq(variables.IS_OTEL_UPGRADE_BRANCH, true)
        variables:
          HELM_CHART_NAME: $[ stageDependencies.Build.Image_Tags_and_Ev2_Artifacts.outputs['setup.HELM_CHART_NAME'] ]
          HELM_SEMVER: $[ stageDependencies.Build.Image_Tags_and_Ev2_Artifacts.outputs['setup.SEMVER'] ]
          IMAGE_TAG: $[ stageDependencies.Build.Image_Tags_and_Ev2_Artifacts.outputs['setup.SEMVER'] ]
          IMAGE_TAG_WINDOWS: $[ stageDependencies.Build.Image_Tags_and_Ev2_Artifacts.outputs['setup.WINDOWS_IMAGE_TAG'] ]
          HELM_FULL_IMAGE_NAME: $[ stageDependencies.Build.Image_Tags_and_Ev2_Artifacts.outputs['setup.HELM_FULL_IMAGE_NAME'] ]
          skipComponentGovernanceDetection: true
        templateContext:
          type: releaseJob
          isProduction: false
          inputs:
          - input: pipelineArtifact
            artifactName: testkube-test-files
            targetPath: $(Pipeline.Workspace)
        strategy:
          runOnce:
            deploy:
              steps:
              - task: AzureCLI@1
                displayName: Get kubeconfig
                inputs:
                  azureSubscription: 'ContainerInsights_Build_Subscription(9b96ebbd-c57a-42d1-bbe9-b69296e4c7fb)'
                  scriptLocation: 'inlineScript'
                  inlineScript: 'az aks get-credentials --resource-group ciprom-upgrade-bot --name ciprom-upgrade-bot'
              - bash: |
                  echo "bot/$(Build.SourceBranchName)"
                  export BUILD_ARTIFACTSTAGINGDIRECTORY="$(Build.ArtifactStagingDirectory)"
                  export BUILD_BUILDID="$(Build.BuildId)"
                  export SYSTEM_JOBID="$(System.JobId)"
                  export SYSTEM_TASKINSTANCEID="$(System.TaskInstanceId)"
                  chmod +x ./testkube/run-testkube-workflow.sh
                  ./testkube/run-testkube-workflow.sh \
                    "https://ciprom-upgrade-bot-e4c4gvcgcqd7awhw.westus3.prometheus.monitor.azure.com" \
                    "3bf21bd6-3dd9-449d-8f17-5f3b1a61ecd6" \
                    "testkube-test-crs-otelcollector-upgrade.yaml" \
                    "testkube-test-crs-otel-upgrade.yaml" \
                    "" \
                    "" \
                    "OTelCollector-Upgrade" \
                    "bot/$(Build.SourceBranchName)"
                workingDirectory: $(Pipeline.Workspace)
                displayName: "Run TestKube workflow"
                continueOnError: true
              - bash: |
                  if [ -f "$(Build.ArtifactStagingDirectory)/testkube-results-OTelCollector-Upgrade.json" ]; then
                    # Read the JSON content and set it as a pipeline variable
                    TESTKUBE_RESULTS_UPGRADE=$(cat "$(Build.ArtifactStagingDirectory)/testkube-results-OTelCollector-Upgrade.json" | jq -c . | tr -d '\n\r')
                    echo "##vso[task.setvariable variable=TESTKUBE_RESULTS_UPGRADE;isOutput=true]$TESTKUBE_RESULTS_UPGRADE"
                    echo "TestKube Upgrade results set as pipeline variable"
                    echo $TESTKUBE_RESULTS_UPGRADE
                  else
                    echo "##vso[task.setvariable variable=TESTKUBE_RESULTS_UPGRADE;isOutput=true]{\"environment\":\"OTelCollector-Upgrade\",\"status\":\"failed\",\"message\":\"Results file not found\"}"
                    echo "TestKube Upgrade results file not found, setting default failure result"
                  fi
                displayName: "Set TestKube Upgrade Results as Pipeline Variable"
                continueOnError: true
                name: testkube_results
              - bash: |
                  if [ -f "$(Build.ArtifactStagingDirectory)/testkube-results-OTelCollector-Upgrade.json" ]; then
                    TEST_STATUS=$(cat "$(Build.ArtifactStagingDirectory)/testkube-results-OTelCollector-Upgrade.json" | jq -r '.status')
                    if [ "$TEST_STATUS" = "failed" ]; then
                      echo "##vso[task.logissue type=error]TestKube tests failed"
                      echo "##vso[task.complete result=Failed;]TestKube tests failed"
                      exit 1
                    fi
                  else
                    echo "##vso[task.logissue type=error]TestKube results file not found"
                    echo "##vso[task.complete result=Failed;]TestKube results file not found"
                    exit 1
                  fi
                displayName: "Fail job if TestKube tests failed"

      - job: TestKube_Summary
        displayName: "Send TestKube Summary Notification"
        pool:
          name: Azure-Pipelines-CI-Test-EO
          image: ci-1es-managed-ubuntu-2204
          os: linux
        dependsOn: 
        - Testkube_ARC
        - Testkube
        - Testkube_OTel
        condition: and(eq(variables.IS_PR, false), eq(variables.IS_MAIN_BRANCH, true))
        variables:
          skipComponentGovernanceDetection: true
          TESTKUBE_RESULTS_ARC: $[ dependencies.Testkube_ARC.outputs['Testkube_ARC.testkube_results.TESTKUBE_RESULTS_ARC'] ]
          TESTKUBE_RESULTS_AKS: $[ dependencies.Testkube.outputs['Testkube.testkube_results.TESTKUBE_RESULTS_AKS'] ]
          TESTKUBE_RESULTS_OTEL: $[ dependencies.Testkube_OTel.outputs['Testkube_OTel.testkube_results.TESTKUBE_RESULTS_OTEL'] ]
        templateContext:
          type: releaseJob
          isProduction: false
          inputs:
          - input: pipelineArtifact
            artifactName: testkube-test-files
            targetPath: $(Pipeline.Workspace)
        steps:
        - bash: |
            # Create results directory
            mkdir -p "$(Pipeline.Workspace)/testkube-results"
            echo "Results directory created"
          displayName: "Create TestKube Results Directory"
        
        # Write ARC results directly to file if available using PowerShell
        - task: PowerShell@2
          displayName: "Write ARC Results"
          condition: and(succeeded(), ne(variables['TESTKUBE_RESULTS_ARC'], ''))
          env:
            TESTKUBE_RESULTS: $(TESTKUBE_RESULTS_ARC)
          inputs:
            targetType: 'inline'
            script: |
              $content = $env:TESTKUBE_RESULTS
              Set-Content -Path "$(Pipeline.Workspace)/testkube-results/testkube-results-ARC.json" -Value $content
        
        # Write AKS results directly to file if available using PowerShell
        - task: PowerShell@2
          displayName: "Write AKS Results"
          condition: and(succeeded(), ne(variables['TESTKUBE_RESULTS_AKS'], ''))
          env:
            TESTKUBE_RESULTS: $(TESTKUBE_RESULTS_AKS)
          inputs:
            targetType: 'inline'
            script: |
              $content = $env:TESTKUBE_RESULTS
              Set-Content -Path "$(Pipeline.Workspace)/testkube-results/testkube-results-AKS.json" -Value $content
        
        # Write OTel results directly to file if available using PowerShell
        - task: PowerShell@2
          displayName: "Write OTel Results"
          condition: and(succeeded(), ne(variables['TESTKUBE_RESULTS_OTEL'], ''))
          env:
            TESTKUBE_RESULTS: $(TESTKUBE_RESULTS_OTEL)
          inputs:
            targetType: 'inline'
            script: |
              $content = $env:TESTKUBE_RESULTS
              Set-Content -Path "$(Pipeline.Workspace)/testkube-results/testkube-results-OTel.json" -Value $content
        
        # List created files
        - bash: |
            echo "Results files created:"
            ls -la "$(Pipeline.Workspace)/testkube-results/"
          displayName: "List Results Files"
        - bash: |
            export SYSTEM_PULLREQUEST_PULLREQUESTTITLE="$(System.PullRequest.PullRequestTitle)"
            export SYSTEM_PULLREQUEST_PULLREQUESTNUMBER="$(System.PullRequest.PullRequestNumber)"
            export BUILD_REASON="$(Build.Reason)"
            export BUILD_SOURCEVERSIONMESSAGE="$(Build.SourceVersionMessage)"
            export BUILD_SOURCEBRANCHNAME="$(Build.SourceBranchName)"
            export BUILD_BUILDNUMBER="$(Build.BuildNumber)"
            chmod +x ./testkube/send-testkube-summary.sh
            ./testkube/send-testkube-summary.sh $(TEAMS_WEBHOOK_URL) $(Pipeline.Workspace)/testkube-results
          workingDirectory: $(Pipeline.Workspace)
          displayName: "Send TestKube Summary Notification"

      - job: TestKube_Notification_OTelCollector_Upgrade
        displayName: "Send TestKube Summary Notification"
        pool:
          name: Azure-Pipelines-CI-Test-EO
          image: ci-1es-managed-ubuntu-2204
          os: linux
        dependsOn: 
        - Testkube_OTel_Upgrade
        condition: eq(variables.IS_OTEL_UPGRADE_BRANCH, true)
        variables:
          skipComponentGovernanceDetection: true
          TESTKUBE_RESULTS_UPGRADE: $[ dependencies.Testkube_OTel_Upgrade.outputs['Testkube_OTel_Upgrade.testkube_results.TESTKUBE_RESULTS_UPGRADE'] ]
        templateContext:
          type: releaseJob
          isProduction: false
          inputs:
          - input: pipelineArtifact
            artifactName: testkube-test-files
            targetPath: $(Pipeline.Workspace)
        steps:
        - bash: |
            # Create results directory
            mkdir -p "$(Pipeline.Workspace)/testkube-results"
            echo "Results directory created"
          displayName: "Create TestKube Results Directory"
        
        # Write Upgrade results directly to file if available using PowerShell
        - task: PowerShell@2
          displayName: "Write Upgrade Results"
          condition: and(succeeded(), ne(variables['TESTKUBE_RESULTS_UPGRADE'], ''))
          env:
            TESTKUBE_RESULTS: $(TESTKUBE_RESULTS_UPGRADE)
          inputs:
            targetType: 'inline'
            script: |
              $content = $env:TESTKUBE_RESULTS
              Set-Content -Path "$(Pipeline.Workspace)/testkube-results/testkube-results-Otel-Upgrade.json" -Value $content
        
        # List created files
        - bash: |
            echo "Results files created:"
            ls -la "$(Pipeline.Workspace)/testkube-results/"
          displayName: "List Results Files"
        - bash: |
            export SYSTEM_PULLREQUEST_PULLREQUESTTITLE="$(System.PullRequest.PullRequestTitle)"
            export SYSTEM_PULLREQUEST_PULLREQUESTNUMBER="$(System.PullRequest.PullRequestNumber)"
            export BUILD_REASON="$(Build.Reason)"
            export BUILD_SOURCEVERSIONMESSAGE="$(Build.SourceVersionMessage)"
            export BUILD_SOURCEBRANCHNAME="$(Build.SourceBranchName)"
            export BUILD_BUILDNUMBER="$(Build.BuildNumber)"
            chmod +x ./testkube/send-testkube-summary.sh
            ./testkube/send-testkube-summary.sh $(TEAMS_WEBHOOK_URL) $(Pipeline.Workspace)/testkube-results
          workingDirectory: $(Pipeline.Workspace)
          displayName: "Send TestKube Summary Notification"
